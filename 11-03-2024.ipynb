{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5fb7fe-757c-4dd5-86a6-aecd58bcbc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f851d496-63e5-41d4-8c06-3ce72b8e802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'MITBIH.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4316ecb2-a820-4343-be2e-b7887c7012bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>type</th>\n",
       "      <th>0_pre-RR</th>\n",
       "      <th>0_post-RR</th>\n",
       "      <th>0_pPeak</th>\n",
       "      <th>0_tPeak</th>\n",
       "      <th>0_rPeak</th>\n",
       "      <th>0_sPeak</th>\n",
       "      <th>0_qPeak</th>\n",
       "      <th>0_qrs_interval</th>\n",
       "      <th>...</th>\n",
       "      <th>1_qPeak</th>\n",
       "      <th>1_qrs_interval</th>\n",
       "      <th>1_pq_interval</th>\n",
       "      <th>1_qt_interval</th>\n",
       "      <th>1_st_interval</th>\n",
       "      <th>1_qrs_morph0</th>\n",
       "      <th>1_qrs_morph1</th>\n",
       "      <th>1_qrs_morph2</th>\n",
       "      <th>1_qrs_morph3</th>\n",
       "      <th>1_qrs_morph4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>76</td>\n",
       "      <td>313</td>\n",
       "      <td>0.074347</td>\n",
       "      <td>-0.160548</td>\n",
       "      <td>1.036401</td>\n",
       "      <td>-0.285662</td>\n",
       "      <td>-0.026824</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.025436</td>\n",
       "      <td>0.025436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>313</td>\n",
       "      <td>315</td>\n",
       "      <td>-0.052079</td>\n",
       "      <td>-0.264784</td>\n",
       "      <td>0.886597</td>\n",
       "      <td>-0.366298</td>\n",
       "      <td>-0.059710</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042009</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.042009</td>\n",
       "      <td>-0.029498</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.030892</td>\n",
       "      <td>0.002986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>315</td>\n",
       "      <td>321</td>\n",
       "      <td>-0.062151</td>\n",
       "      <td>-0.296983</td>\n",
       "      <td>0.991859</td>\n",
       "      <td>-0.410306</td>\n",
       "      <td>-0.065686</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.008368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>321</td>\n",
       "      <td>336</td>\n",
       "      <td>-0.063322</td>\n",
       "      <td>-0.281386</td>\n",
       "      <td>1.034903</td>\n",
       "      <td>-0.403880</td>\n",
       "      <td>-0.071750</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020536</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.020536</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.018965</td>\n",
       "      <td>-0.016968</td>\n",
       "      <td>-0.014555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>336</td>\n",
       "      <td>344</td>\n",
       "      <td>-0.062915</td>\n",
       "      <td>1.046914</td>\n",
       "      <td>1.046408</td>\n",
       "      <td>1.046408</td>\n",
       "      <td>-0.074639</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>-0.007798</td>\n",
       "      <td>-0.051155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   record type  0_pre-RR  0_post-RR   0_pPeak   0_tPeak   0_rPeak   0_sPeak  \\\n",
       "0     101    N        76        313  0.074347 -0.160548  1.036401 -0.285662   \n",
       "1     101    N       313        315 -0.052079 -0.264784  0.886597 -0.366298   \n",
       "2     101    N       315        321 -0.062151 -0.296983  0.991859 -0.410306   \n",
       "3     101    N       321        336 -0.063322 -0.281386  1.034903 -0.403880   \n",
       "4     101    N       336        344 -0.062915  1.046914  1.046408  1.046408   \n",
       "\n",
       "    0_qPeak  0_qrs_interval  ...   1_qPeak  1_qrs_interval  1_pq_interval  \\\n",
       "0 -0.026824              41  ...  0.025930               2             18   \n",
       "1 -0.059710              21  ... -0.042009              26             27   \n",
       "2 -0.065686              22  ...  0.009528               3              8   \n",
       "3 -0.071750              22  ... -0.020536               6              9   \n",
       "4 -0.074639              11  ...  0.016053              16              5   \n",
       "\n",
       "   1_qt_interval  1_st_interval  1_qrs_morph0  1_qrs_morph1  1_qrs_morph2  \\\n",
       "0             22              2      0.025930      0.025930      0.025930   \n",
       "1             62              9     -0.042009     -0.029498      0.005012   \n",
       "2             12              1      0.009528      0.009528      0.008786   \n",
       "3             16              1     -0.020536     -0.020257     -0.018965   \n",
       "4             31             10      0.016053      0.006742      0.002782   \n",
       "\n",
       "   1_qrs_morph3  1_qrs_morph4  \n",
       "0      0.025436      0.025436  \n",
       "1      0.030892      0.002986  \n",
       "2      0.008786      0.008368  \n",
       "3     -0.016968     -0.014555  \n",
       "4     -0.007798     -0.051155  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90225bd6-b84d-410a-b36e-e4315c7c7b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5011b4f1-2912-40f8-8e80-a2a6e2e9722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0321d5d2-eaae-4318-abbb-0be8d2ce053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['record'], axis=1)\n",
    "y = data['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a055e5c-8488-4f6a-a212-99f21b11b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dbb8b5b-5d4e-49b4-b8ee-bed1b879614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100689, 34)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83bb7450-9cdb-4dfc-8d09-6c4b7516a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80551, 33)\n",
      "(20138, 33)\n",
      "(80551,)\n",
      "(20138,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c8012a4-aef4-4930-b392-f1cbfc5c382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training set to a CSV file\n",
    "train_data = pd.concat([X_train, y_train], axis=1)  # Concatenate features and target\n",
    "train_data.to_csv('./train_dataset.csv', index=False)\n",
    "\n",
    "# Save the testing set to a CSV file\n",
    "test_data = pd.concat([X_test, y_test], axis=1)  # Concatenate features and target\n",
    "test_data.to_csv('./test_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ce7852c-dc07-4678-bf58-7691a11fe2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in the dataset:\n",
      "Index(['type', '0_pre-RR', '0_post-RR', '0_pPeak', '0_tPeak', '0_rPeak',\n",
      "       '0_sPeak', '0_qPeak', '0_qrs_interval', '0_pq_interval',\n",
      "       '0_qt_interval', '0_st_interval', '0_qrs_morph0', '0_qrs_morph1',\n",
      "       '0_qrs_morph2', '0_qrs_morph3', '0_qrs_morph4', '1_pre-RR', '1_post-RR',\n",
      "       '1_pPeak', '1_tPeak', '1_rPeak', '1_sPeak', '1_qPeak', '1_qrs_interval',\n",
      "       '1_pq_interval', '1_qt_interval', '1_st_interval', '1_qrs_morph0',\n",
      "       '1_qrs_morph1', '1_qrs_morph2', '1_qrs_morph3', '1_qrs_morph4'],\n",
      "      dtype='object')\n",
      "Target variable column 'your_target_column' not found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"MITBIH.csv\"  # Replace with the actual path to your dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Drop 'record' column\n",
    "df = df.drop('record', axis=1, errors='ignore')\n",
    "\n",
    "# Display available columns\n",
    "print(\"Available columns in the dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Identify feature columns\n",
    "feature_columns = df.columns\n",
    "\n",
    "# Check if there are any valid feature columns\n",
    "if len(feature_columns) == 0:\n",
    "    print(\"No valid feature columns found.\")\n",
    "else:\n",
    "    # Choose the target variable (replace 'your_target_column' with the actual column name)\n",
    "    target_column = 'your_target_column'  # Replace with the actual target variable column name\n",
    "\n",
    "    # Check if the target column exists\n",
    "    if target_column not in df.columns:\n",
    "        print(f\"Target variable column '{target_column}' not found in the dataset.\")\n",
    "    else:\n",
    "        # Separate features (X) and target variable (y)\n",
    "        X = df.drop(target_column, axis=1, errors='ignore')\n",
    "        y = df[target_column]\n",
    "\n",
    "        # Train-test split (80% train, 20% test)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Perform standard scaling on the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Convert y to a 1D array before fitting the scaler\n",
    "        y_train = y_train.values.ravel()\n",
    "        y_test = y_test.values.ravel()\n",
    "\n",
    "        # Construct paths for saving preprocessed datasets\n",
    "        base_path = os.path.dirname(dataset_path)\n",
    "        preprocessed_train_path = os.path.join(base_path, \"train.csv\")\n",
    "        preprocessed_test_path = os.path.join(base_path, \"test.csv\")\n",
    "\n",
    "        # Save the preprocessed datasets\n",
    "        pd.DataFrame(X_train_scaled, columns=X.columns).to_csv(preprocessed_train_path, index=False)\n",
    "        pd.DataFrame(X_test_scaled, columns=X.columns).to_csv(preprocessed_test_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1eaf4a4-17eb-444f-9f42-9d62be06959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wfdb in c:\\users\\yarra\\anaconda3\\lib\\site-packages (4.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: SoundFile>=0.10.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from wfdb) (0.12.1)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from wfdb) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.10.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from wfdb) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from wfdb) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.8.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from wfdb) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from wfdb) (1.11.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->wfdb) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->wfdb) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests>=2.8.1->wfdb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests>=2.8.1->wfdb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests>=2.8.1->wfdb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests>=2.8.1->wfdb) (2024.2.2)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from SoundFile>=0.10.0->wfdb) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5e8911-06a5-466b-b2c8-f67aa5538421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\yarra\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f96934b4-479a-4ad5-ba46-162b7d162bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in the dataset:\n",
      "Index(['type', '0_pre-RR', '0_post-RR', '0_pPeak', '0_tPeak', '0_rPeak',\n",
      "       '0_sPeak', '0_qPeak', '0_qrs_interval', '0_pq_interval',\n",
      "       '0_qt_interval', '0_st_interval', '0_qrs_morph0', '0_qrs_morph1',\n",
      "       '0_qrs_morph2', '0_qrs_morph3', '0_qrs_morph4', '1_pre-RR', '1_post-RR',\n",
      "       '1_pPeak', '1_tPeak', '1_rPeak', '1_sPeak', '1_qPeak', '1_qrs_interval',\n",
      "       '1_pq_interval', '1_qt_interval', '1_st_interval', '1_qrs_morph0',\n",
      "       '1_qrs_morph1', '1_qrs_morph2', '1_qrs_morph3', '1_qrs_morph4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"MITBIH.csv\"  # Replace with the actual path to your dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Drop 'record' column\n",
    "df = df.drop('record', axis=1, errors='ignore')\n",
    "\n",
    "# Display available columns\n",
    "print(\"Available columns in the dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Identify feature columns\n",
    "feature_columns = df.columns\n",
    "\n",
    "# Check if there are any valid feature columns\n",
    "if len(feature_columns) == 0:\n",
    "    print(\"No valid feature columns found.\")\n",
    "else:\n",
    "    # Choose the target variable ('type' in this case)\n",
    "    target_column = 'type'\n",
    "\n",
    "    # Check if the target column exists\n",
    "    if target_column not in df.columns:\n",
    "        print(f\"Target variable column '{target_column}' not found in the dataset.\")\n",
    "    else:\n",
    "        # Separate features (X) and target variable (y)\n",
    "        X = df.drop(target_column, axis=1, errors='ignore')\n",
    "        y = df[target_column]\n",
    "\n",
    "        # Train-test split (80% train, 20% test)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Perform standard scaling on the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Convert y to a 1D array before fitting the scaler\n",
    "        y_train = y_train.values.ravel()\n",
    "        y_test = y_test.values.ravel()\n",
    "\n",
    "        # Construct paths for saving preprocessed datasets\n",
    "        base_path = os.path.dirname(dataset_path)\n",
    "        preprocessed_train_path = os.path.join(base_path, \"train.csv\")\n",
    "        preprocessed_test_path = os.path.join(base_path, \"test.csv\")\n",
    "\n",
    "        # Save the preprocessed datasets\n",
    "        pd.DataFrame(X_train_scaled, columns=X.columns).to_csv(preprocessed_train_path, index=False)\n",
    "        pd.DataFrame(X_test_scaled, columns=X.columns).to_csv(preprocessed_test_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c135d3e-99c6-4b00-b7e8-0e8e86741f44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'N'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Convert the target variable to a numeric type\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[0;32m     21\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    416\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    417\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    418\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    419\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'N'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)  # Remove 'record' from the list of columns to drop\n",
    "y = df['type']\n",
    "\n",
    "# Convert the target variable to a numeric type\n",
    "y = y.astype(float)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for LSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ce32a35-8d0f-40f1-a9eb-28e3869149ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8673 - loss: -6.5974 - val_accuracy: 0.8958 - val_loss: -26.5266\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: -31.9591 - val_accuracy: 0.8971 - val_loss: -49.2347\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: -54.6653 - val_accuracy: 0.8953 - val_loss: -71.4159\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: -78.7626 - val_accuracy: 0.8967 - val_loss: -93.8092\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8949 - loss: -100.7358 - val_accuracy: 0.8960 - val_loss: -115.9307\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: -121.8350 - val_accuracy: 0.8969 - val_loss: -138.2230\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: -141.4566 - val_accuracy: 0.8974 - val_loss: -160.5357\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: -168.7274 - val_accuracy: 0.8951 - val_loss: -182.5291\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: -187.5170 - val_accuracy: 0.8977 - val_loss: -204.8041\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: -215.3316 - val_accuracy: 0.8977 - val_loss: -227.0941\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.38      0.53       150\n",
      "           1       0.90      1.00      0.95     18029\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00       582\n",
      "           4       0.00      0.00      0.00      1376\n",
      "\n",
      "    accuracy                           0.90     20138\n",
      "   macro avg       0.35      0.28      0.29     20138\n",
      "weighted avg       0.81      0.90      0.85     20138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)  # Remove 'record' from the list of columns to drop\n",
    "y = df['type']\n",
    "\n",
    "# Use LabelEncoder to convert string labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for LSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6be1891-46f5-46a0-8eb5-5642a64d5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 19ms/step - accuracy: 0.8932 - loss: -9.2201 - val_accuracy: 0.8953 - val_loss: -30.3855\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 20ms/step - accuracy: 0.8944 - loss: -37.5418 - val_accuracy: 0.8953 - val_loss: -57.5708\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 19ms/step - accuracy: 0.8944 - loss: -64.8467 - val_accuracy: 0.8953 - val_loss: -84.9406\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 20ms/step - accuracy: 0.8972 - loss: -89.9179 - val_accuracy: 0.8953 - val_loss: -112.3347\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 19ms/step - accuracy: 0.8947 - loss: -119.2831 - val_accuracy: 0.8953 - val_loss: -139.6385\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 19ms/step - accuracy: 0.8946 - loss: -146.6934 - val_accuracy: 0.8953 - val_loss: -167.0335\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 19ms/step - accuracy: 0.8965 - loss: -171.4209 - val_accuracy: 0.8953 - val_loss: -194.4572\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 19ms/step - accuracy: 0.8946 - loss: -203.7428 - val_accuracy: 0.8953 - val_loss: -221.5240\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 19ms/step - accuracy: 0.8938 - loss: -232.4745 - val_accuracy: 0.8953 - val_loss: -248.8937\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 19ms/step - accuracy: 0.8929 - loss: -259.5642 - val_accuracy: 0.8953 - val_loss: -276.2146\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       150\n",
      "           1       0.90      1.00      0.94     18029\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00       582\n",
      "           4       0.00      0.00      0.00      1376\n",
      "\n",
      "    accuracy                           0.90     20138\n",
      "   macro avg       0.18      0.20      0.19     20138\n",
      "weighted avg       0.80      0.90      0.85     20138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Flatten, Input\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)  # Remove 'record' from the list of columns to drop\n",
    "y = df['type']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for CNN+LSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Build the CNN+LSTM model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae7612bb-7b05-4f7d-b2da-89ccb7de0110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 69ms/step - accuracy: 0.8942 - loss: -17.7450 - val_accuracy: 0.8953 - val_loss: -60.8177\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 61ms/step - accuracy: 0.8947 - loss: -75.5680 - val_accuracy: 0.8953 - val_loss: -117.5386\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 65ms/step - accuracy: 0.8935 - loss: -133.2752 - val_accuracy: 0.8953 - val_loss: -173.6372\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 64ms/step - accuracy: 0.8964 - loss: -185.8689 - val_accuracy: 0.8953 - val_loss: -230.1750\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 62ms/step - accuracy: 0.8944 - loss: -245.4667 - val_accuracy: 0.8953 - val_loss: -286.3735\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 62ms/step - accuracy: 0.8958 - loss: -299.3679 - val_accuracy: 0.8953 - val_loss: -343.0522\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 62ms/step - accuracy: 0.8958 - loss: -353.6588 - val_accuracy: 0.8953 - val_loss: -399.3307\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 61ms/step - accuracy: 0.8963 - loss: -410.3179 - val_accuracy: 0.8953 - val_loss: -455.8328\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 64ms/step - accuracy: 0.8960 - loss: -463.7467 - val_accuracy: 0.8953 - val_loss: -512.1761\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 69ms/step - accuracy: 0.8939 - loss: -530.5942 - val_accuracy: 0.8953 - val_loss: -568.4420\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       150\n",
      "           1       0.90      1.00      0.94     18029\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00       582\n",
      "           4       0.00      0.00      0.00      1376\n",
      "\n",
      "    accuracy                           0.90     20138\n",
      "   macro avg       0.18      0.20      0.19     20138\n",
      "weighted avg       0.80      0.90      0.85     20138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Bidirectional\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for BiLSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Build the BiLSTM model with Conv1D\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(50)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8848572-e34d-4afe-8c23-9631329f819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/binary_crossentropy/Cast defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\yarra\\AppData\\Local\\Temp\\ipykernel_27884\\1055325094.py\", line 37, in <module>\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 323, in fit\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 105, in one_step_on_data\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 59, in train_step\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 321, in compute_loss\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 606, in __call__\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 642, in call\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 39, in __call__\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\tree\\__init__.py\", line 435, in map_structure\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\tree\\__init__.py\", line 435, in <listcomp>\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 40, in <lambda>\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\core.py\", line 493, in convert_to_tensor\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py\", line 117, in convert_to_tensor\n\nCast string to float is not supported\n\t [[{{node compile_loss/binary_crossentropy/Cast}}]] [Op:__inference_one_step_on_iterator_547923]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_reshaped, y_test))\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_reshaped)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/binary_crossentropy/Cast defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\yarra\\AppData\\Local\\Temp\\ipykernel_27884\\1055325094.py\", line 37, in <module>\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 323, in fit\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 105, in one_step_on_data\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 59, in train_step\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 321, in compute_loss\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 606, in __call__\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 642, in call\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 39, in __call__\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\tree\\__init__.py\", line 435, in map_structure\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\tree\\__init__.py\", line 435, in <listcomp>\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 40, in <lambda>\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\core.py\", line 493, in convert_to_tensor\n\n  File \"C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py\", line 117, in convert_to_tensor\n\nCast string to float is not supported\n\t [[{{node compile_loss/binary_crossentropy/Cast}}]] [Op:__inference_one_step_on_iterator_547923]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)  # Remove 'record' from the list of columns to drop\n",
    "y = df['type']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for RNN + LSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Build the RNN + LSTM model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9425738b-e883-4feb-bc98-2c394b221fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>type</th>\n",
       "      <th>0_pre-RR</th>\n",
       "      <th>0_post-RR</th>\n",
       "      <th>0_pPeak</th>\n",
       "      <th>0_tPeak</th>\n",
       "      <th>0_rPeak</th>\n",
       "      <th>0_sPeak</th>\n",
       "      <th>0_qPeak</th>\n",
       "      <th>0_qrs_interval</th>\n",
       "      <th>...</th>\n",
       "      <th>1_qPeak</th>\n",
       "      <th>1_qrs_interval</th>\n",
       "      <th>1_pq_interval</th>\n",
       "      <th>1_qt_interval</th>\n",
       "      <th>1_st_interval</th>\n",
       "      <th>1_qrs_morph0</th>\n",
       "      <th>1_qrs_morph1</th>\n",
       "      <th>1_qrs_morph2</th>\n",
       "      <th>1_qrs_morph3</th>\n",
       "      <th>1_qrs_morph4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>76</td>\n",
       "      <td>313</td>\n",
       "      <td>0.074347</td>\n",
       "      <td>-0.160548</td>\n",
       "      <td>1.036401</td>\n",
       "      <td>-0.285662</td>\n",
       "      <td>-0.026824</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.025436</td>\n",
       "      <td>0.025436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>313</td>\n",
       "      <td>315</td>\n",
       "      <td>-0.052079</td>\n",
       "      <td>-0.264784</td>\n",
       "      <td>0.886597</td>\n",
       "      <td>-0.366298</td>\n",
       "      <td>-0.059710</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042009</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.042009</td>\n",
       "      <td>-0.029498</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.030892</td>\n",
       "      <td>0.002986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>315</td>\n",
       "      <td>321</td>\n",
       "      <td>-0.062151</td>\n",
       "      <td>-0.296983</td>\n",
       "      <td>0.991859</td>\n",
       "      <td>-0.410306</td>\n",
       "      <td>-0.065686</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.008368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>321</td>\n",
       "      <td>336</td>\n",
       "      <td>-0.063322</td>\n",
       "      <td>-0.281386</td>\n",
       "      <td>1.034903</td>\n",
       "      <td>-0.403880</td>\n",
       "      <td>-0.071750</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020536</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.020536</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.018965</td>\n",
       "      <td>-0.016968</td>\n",
       "      <td>-0.014555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>336</td>\n",
       "      <td>344</td>\n",
       "      <td>-0.062915</td>\n",
       "      <td>1.046914</td>\n",
       "      <td>1.046408</td>\n",
       "      <td>1.046408</td>\n",
       "      <td>-0.074639</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>-0.007798</td>\n",
       "      <td>-0.051155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   record type  0_pre-RR  0_post-RR   0_pPeak   0_tPeak   0_rPeak   0_sPeak  \\\n",
       "0     101    N        76        313  0.074347 -0.160548  1.036401 -0.285662   \n",
       "1     101    N       313        315 -0.052079 -0.264784  0.886597 -0.366298   \n",
       "2     101    N       315        321 -0.062151 -0.296983  0.991859 -0.410306   \n",
       "3     101    N       321        336 -0.063322 -0.281386  1.034903 -0.403880   \n",
       "4     101    N       336        344 -0.062915  1.046914  1.046408  1.046408   \n",
       "\n",
       "    0_qPeak  0_qrs_interval  ...   1_qPeak  1_qrs_interval  1_pq_interval  \\\n",
       "0 -0.026824              41  ...  0.025930               2             18   \n",
       "1 -0.059710              21  ... -0.042009              26             27   \n",
       "2 -0.065686              22  ...  0.009528               3              8   \n",
       "3 -0.071750              22  ... -0.020536               6              9   \n",
       "4 -0.074639              11  ...  0.016053              16              5   \n",
       "\n",
       "   1_qt_interval  1_st_interval  1_qrs_morph0  1_qrs_morph1  1_qrs_morph2  \\\n",
       "0             22              2      0.025930      0.025930      0.025930   \n",
       "1             62              9     -0.042009     -0.029498      0.005012   \n",
       "2             12              1      0.009528      0.009528      0.008786   \n",
       "3             16              1     -0.020536     -0.020257     -0.018965   \n",
       "4             31             10      0.016053      0.006742      0.002782   \n",
       "\n",
       "   1_qrs_morph3  1_qrs_morph4  \n",
       "0      0.025436      0.025436  \n",
       "1      0.030892      0.002986  \n",
       "2      0.008786      0.008368  \n",
       "3     -0.016968     -0.014555  \n",
       "4     -0.007798     -0.051155  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5eb5261-fb08-4805-b0d1-c74f615ce74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in the dataset:\n",
      "Index(['type', '0_pre-RR', '0_post-RR', '0_pPeak', '0_tPeak', '0_rPeak',\n",
      "       '0_sPeak', '0_qPeak', '0_qrs_interval', '0_pq_interval',\n",
      "       '0_qt_interval', '0_st_interval', '0_qrs_morph0', '0_qrs_morph1',\n",
      "       '0_qrs_morph2', '0_qrs_morph3', '0_qrs_morph4', '1_pre-RR', '1_post-RR',\n",
      "       '1_pPeak', '1_tPeak', '1_rPeak', '1_sPeak', '1_qPeak', '1_qrs_interval',\n",
      "       '1_pq_interval', '1_qt_interval', '1_st_interval', '1_qrs_morph0',\n",
      "       '1_qrs_morph1', '1_qrs_morph2', '1_qrs_morph3', '1_qrs_morph4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"MITBIH.csv\"  # Replace with the actual path to your dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Drop 'record' column\n",
    "df = df.drop('record', axis=1, errors='ignore')\n",
    "\n",
    "# Display available columns\n",
    "print(\"Available columns in the dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Identify feature columns\n",
    "feature_columns = df.columns\n",
    "\n",
    "# Check if there are any valid feature columns\n",
    "if len(feature_columns) == 0:\n",
    "    print(\"No valid feature columns found.\")\n",
    "else:\n",
    "    # Choose the target variable ('type' in this case)\n",
    "    target_column = 'type'\n",
    "\n",
    "    # Check if the target column exists\n",
    "    if target_column not in df.columns:\n",
    "        print(f\"Target variable column '{target_column}' not found in the dataset.\")\n",
    "    else:\n",
    "        # Separate features (X) and target variable (y)\n",
    "        X = df.drop(target_column, axis=1, errors='ignore')\n",
    "        y = df[target_column]\n",
    "\n",
    "        # Train-test split (80% train, 20% test)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Perform standard scaling on the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Convert y to a 1D array before fitting the scaler\n",
    "        y_train = y_train.values.ravel()\n",
    "        y_test = y_test.values.ravel()\n",
    "\n",
    "        # Construct paths for saving preprocessed datasets\n",
    "        base_path = os.path.dirname(dataset_path)\n",
    "        preprocessed_train_path = os.path.join(base_path, \"train.csv\")\n",
    "        preprocessed_test_path = os.path.join(base_path, \"test.csv\")\n",
    "\n",
    "        # Save the preprocessed datasets\n",
    "        pd.DataFrame(X_train_scaled, columns=X.columns).to_csv(preprocessed_train_path, index=False)\n",
    "        pd.DataFrame(X_test_scaled, columns=X.columns).to_csv(preprocessed_test_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e69a0ee-a01b-4e1d-9d11-ecce02d74e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 68ms/step - accuracy: 0.8944 - loss: -17.5774 - val_accuracy: 0.8953 - val_loss: -60.6203\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.8937 - loss: -76.0207 - val_accuracy: 0.8953 - val_loss: -117.0386\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.8943 - loss: -133.2774 - val_accuracy: 0.8953 - val_loss: -173.3966\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.8958 - loss: -185.5215 - val_accuracy: 0.8953 - val_loss: -229.6671\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 65ms/step - accuracy: 0.8928 - loss: -248.4494 - val_accuracy: 0.8953 - val_loss: -285.8077\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.8924 - loss: -305.9892 - val_accuracy: 0.8953 - val_loss: -342.3698\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 70ms/step - accuracy: 0.8952 - loss: -357.8571 - val_accuracy: 0.8953 - val_loss: -399.2740\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.8927 - loss: -421.9197 - val_accuracy: 0.8953 - val_loss: -455.2724\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 62ms/step - accuracy: 0.8958 - loss: -465.7663 - val_accuracy: 0.8953 - val_loss: -511.9254\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 64ms/step - accuracy: 0.8955 - loss: -523.2632 - val_accuracy: 0.8953 - val_loss: -568.2703\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       150\n",
      "           1       0.90      1.00      0.94     18029\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00       582\n",
      "           4       0.00      0.00      0.00      1376\n",
      "\n",
      "    accuracy                           0.90     20138\n",
      "   macro avg       0.18      0.20      0.19     20138\n",
      "weighted avg       0.80      0.90      0.85     20138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Bidirectional\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for BiLSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Build the BiLSTM model with Conv1D\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(50)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37dc2cea-3906-4717-935d-9a962263350e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: -6.5361 - val_accuracy: 0.8955 - val_loss: -26.4669\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: -32.8889 - val_accuracy: 0.8957 - val_loss: -49.0323\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: -55.9470 - val_accuracy: 0.8972 - val_loss: -71.3274\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: -77.4145 - val_accuracy: 0.8963 - val_loss: -93.5495\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: -102.2674 - val_accuracy: 0.8968 - val_loss: -115.7945\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8971 - loss: -119.7790 - val_accuracy: 0.8974 - val_loss: -138.2220\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: -142.7670 - val_accuracy: 0.8976 - val_loss: -160.4585\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: -167.6708 - val_accuracy: 0.8976 - val_loss: -182.7007\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: -188.5434 - val_accuracy: 0.8976 - val_loss: -204.9153\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: -213.0906 - val_accuracy: 0.8967 - val_loss: -226.9730\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.35      0.46       150\n",
      "           1       0.90      1.00      0.95     18029\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00       582\n",
      "           4       0.00      0.00      0.00      1376\n",
      "\n",
      "    accuracy                           0.90     20138\n",
      "   macro avg       0.32      0.27      0.28     20138\n",
      "weighted avg       0.81      0.90      0.85     20138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for LSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57941dc0-edf8-4d51-9f74-46108f78979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: -6.4787 - val_accuracy: 0.8952 - val_loss: -26.2370\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8946 - loss: -32.6575 - val_accuracy: 0.8969 - val_loss: -48.7959\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: -55.0117 - val_accuracy: 0.8973 - val_loss: -71.1978\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: -76.8652 - val_accuracy: 0.8965 - val_loss: -93.5267\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8970 - loss: -98.7619 - val_accuracy: 0.8967 - val_loss: -115.7709\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: -123.4704 - val_accuracy: 0.8973 - val_loss: -138.0001\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: -146.1414 - val_accuracy: 0.8950 - val_loss: -160.2320\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: -171.0411 - val_accuracy: 0.8977 - val_loss: -182.3816\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8970 - loss: -188.6021 - val_accuracy: 0.8976 - val_loss: -204.7101\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: -214.0037 - val_accuracy: 0.8979 - val_loss: -227.0167\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.37      0.53       150\n",
      "         1.0       0.90      1.00      0.95     18029\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         3.0       0.00      0.00      0.00       582\n",
      "         4.0       0.00      0.00      0.00      1376\n",
      "\n",
      "    accuracy                           0.90     20138\n",
      "   macro avg       0.37      0.27      0.29     20138\n",
      "weighted avg       0.81      0.90      0.85     20138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert y to float\n",
    "y = y.astype(float)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for LSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Build the LSTM model with explicit input_shape\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1a075ba-aaf3-4453-9d7f-ef02e3061892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 21ms/step - accuracy: 0.8950 - loss: -9.8678 - val_accuracy: 0.8953 - val_loss: -31.3261\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 20ms/step - accuracy: 0.8947 - loss: -38.4964 - val_accuracy: 0.8953 - val_loss: -59.9761\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 19ms/step - accuracy: 0.8941 - loss: -68.0183 - val_accuracy: 0.8953 - val_loss: -88.3170\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 19ms/step - accuracy: 0.8945 - loss: -95.5882 - val_accuracy: 0.8953 - val_loss: -117.0956\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 19ms/step - accuracy: 0.8950 - loss: -123.8876 - val_accuracy: 0.8953 - val_loss: -145.5810\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 19ms/step - accuracy: 0.8937 - loss: -154.9223 - val_accuracy: 0.8953 - val_loss: -173.9538\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 19ms/step - accuracy: 0.8950 - loss: -182.5240 - val_accuracy: 0.8953 - val_loss: -202.4391\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 19ms/step - accuracy: 0.8937 - loss: -213.0422 - val_accuracy: 0.8953 - val_loss: -230.9601\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 18ms/step - accuracy: 0.8954 - loss: -237.9294 - val_accuracy: 0.8953 - val_loss: -259.3922\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 19ms/step - accuracy: 0.8927 - loss: -272.1238 - val_accuracy: 0.8953 - val_loss: -287.6793\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       150\n",
      "         1.0       0.90      1.00      0.94     18029\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         3.0       0.00      0.00      0.00       582\n",
      "         4.0       0.00      0.00      0.00      1376\n",
      "\n",
      "    accuracy                           0.90     20138\n",
      "   macro avg       0.18      0.20      0.19     20138\n",
      "weighted avg       0.80      0.90      0.85     20138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Flatten\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert y to float\n",
    "y = y.astype(float)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for CNN+LSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Build the CNN+LSTM model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8b63b9b-67b0-4dd0-8742-b3dc33c2c724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8840 - loss: -12284.0010 - val_accuracy: 0.8953 - val_loss: -172864.2188\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: -327407.6875 - val_accuracy: 0.8953 - val_loss: -977466.1250\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: -1327306.7500 - val_accuracy: 0.8953 - val_loss: -2638244.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: -3335295.0000 - val_accuracy: 0.8953 - val_loss: -5323162.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8952 - loss: -6379667.5000 - val_accuracy: 0.8953 - val_loss: -9307095.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8957 - loss: -10432012.0000 - val_accuracy: 0.8953 - val_loss: -14770334.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: -16543120.0000 - val_accuracy: 0.8953 - val_loss: -21788426.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: -24345806.0000 - val_accuracy: 0.8953 - val_loss: -30653098.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: -33874424.0000 - val_accuracy: 0.8953 - val_loss: -41377400.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: -45692276.0000 - val_accuracy: 0.8953 - val_loss: -54139872.0000\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       150\n",
      "         1.0       0.90      1.00      0.94     18029\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         3.0       0.00      0.00      0.00       582\n",
      "         4.0       0.00      0.00      0.00      1376\n",
      "\n",
      "    accuracy                           0.90     20138\n",
      "   macro avg       0.18      0.20      0.19     20138\n",
      "weighted avg       0.80      0.90      0.85     20138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert y to float\n",
    "y = y.astype(float)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for RNN + LSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Build the RNN + LSTM model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ddcf2d4-f4f3-4038-a371-98d64c2175a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical  # Import to_categorical\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y.astype(str))  # Convert all values to strings\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01d5fdb6-946d-448b-a3ee-0873e4fc68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming 'your_dataset.csv' is your dataset file\n",
    "dataset_path = 'MITBIH.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['record', 'type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y.astype(str))  # Convert all values to strings\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now you can use X_train, X_test, y_train, y_test for further processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc66f06e-a285-4776-8ef4-4f73e5e40d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9201 - loss: 0.4468 - val_accuracy: 0.9494 - val_loss: 0.1836\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.1932 - val_accuracy: 0.9520 - val_loss: 0.1501\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9497 - loss: 0.1660 - val_accuracy: 0.9563 - val_loss: 0.1395\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 0.1410 - val_accuracy: 0.9594 - val_loss: 0.1199\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.1256 - val_accuracy: 0.9634 - val_loss: 0.1149\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.1108 - val_accuracy: 0.9680 - val_loss: 0.1118\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.1018 - val_accuracy: 0.9670 - val_loss: 0.1021\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9706 - loss: 0.0969 - val_accuracy: 0.9732 - val_loss: 0.0914\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.0913 - val_accuracy: 0.9744 - val_loss: 0.0886\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9734 - loss: 0.0880 - val_accuracy: 0.9743 - val_loss: 0.0861\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.82      0.62      0.70       150\n",
      "           N       0.99      0.99      0.99     18029\n",
      "           Q       0.00      0.00      0.00         1\n",
      "        SVEB       0.83      0.71      0.76       582\n",
      "         VEB       0.88      0.94      0.91      1376\n",
      "\n",
      "    accuracy                           0.97     20138\n",
      "   macro avg       0.70      0.65      0.67     20138\n",
      "weighted avg       0.97      0.97      0.97     20138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming 'your_dataset.csv' is your dataset file\n",
    "dataset_path = 'MITBIH.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['record', 'type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y.astype(str))  # Convert all values to strings\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = y_pred_prob.argmax(axis=1)\n",
    "\n",
    "# Convert predictions back to original labels\n",
    "y_pred_original = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Convert true labels back to original labels\n",
    "y_true_original = label_encoder.inverse_transform(y_test.argmax(axis=1))\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_original, y_pred_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1df03fa-82b8-42a9-8476-4168370d41a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9199 - loss: 0.5256 - val_accuracy: 0.9107 - val_loss: 0.3257\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.1814 - val_accuracy: 0.9362 - val_loss: 0.2040\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.1499 - val_accuracy: 0.9550 - val_loss: 0.1321\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9605 - loss: 0.1273 - val_accuracy: 0.9676 - val_loss: 0.1175\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.1114 - val_accuracy: 0.9718 - val_loss: 0.0931\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0935 - val_accuracy: 0.9749 - val_loss: 0.0848\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0849 - val_accuracy: 0.9756 - val_loss: 0.0828\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0758 - val_accuracy: 0.9781 - val_loss: 0.0743\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0709 - val_accuracy: 0.9800 - val_loss: 0.0689\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.0697 - val_accuracy: 0.9783 - val_loss: 0.0780\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 24ms/step - accuracy: 0.9081 - loss: 1.0998 - val_accuracy: 0.9455 - val_loss: 0.1887\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 21ms/step - accuracy: 0.9432 - loss: 1.0747 - val_accuracy: 0.9195 - val_loss: 0.3679\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 20ms/step - accuracy: 0.9302 - loss: 0.2954 - val_accuracy: 0.9466 - val_loss: 0.1861\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 20ms/step - accuracy: 0.9437 - loss: 0.1994 - val_accuracy: 0.9325 - val_loss: 0.2095\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 21ms/step - accuracy: 0.9417 - loss: 0.3401 - val_accuracy: 0.9506 - val_loss: 0.1581\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 20ms/step - accuracy: 0.9537 - loss: 0.1598 - val_accuracy: 0.9491 - val_loss: 0.1720\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 21ms/step - accuracy: 0.9602 - loss: 0.1348 - val_accuracy: 0.9692 - val_loss: 0.1036\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 20ms/step - accuracy: 0.9702 - loss: 0.0992 - val_accuracy: 0.9694 - val_loss: 0.1013\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 21ms/step - accuracy: 0.9739 - loss: 0.0898 - val_accuracy: 0.9711 - val_loss: 0.0880\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 21ms/step - accuracy: 0.9769 - loss: 0.0793 - val_accuracy: 0.9792 - val_loss: 0.0759\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m bilstm_model\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_reshaped, y_test))\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Make predictions using CNN model\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m y_pred_cnn \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mpredict_classes(X_test_reshaped)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Make predictions using BiLSTM model\u001b[39;00m\n\u001b[0;32m     58\u001b[0m y_pred_bilstm_prob \u001b[38;5;241m=\u001b[39m bilstm_model\u001b[38;5;241m.\u001b[39mpredict(X_test_reshaped)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, Bidirectional, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MIT-BIH Arrhythmia dataset\n",
    "# Assuming 'mitbih.csv' is your dataset file\n",
    "dataset_path = 'MITBIH.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the CNN model\n",
    "cnn_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Build the BiLSTM model\n",
    "bilstm_model = Sequential()\n",
    "bilstm_model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1))))\n",
    "bilstm_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "bilstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the BiLSTM model\n",
    "bilstm_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions using CNN model\n",
    "y_pred_cnn = cnn_model.predict_classes(X_test_reshaped)\n",
    "\n",
    "# Make predictions using BiLSTM model\n",
    "y_pred_bilstm_prob = bilstm_model.predict(X_test_reshaped)\n",
    "y_pred_bilstm = y_pred_bilstm_prob.argmax(axis=1)\n",
    "\n",
    "# Convert true labels back to original labels\n",
    "y_true_original = label_encoder.inverse_transform(y_test.argmax(axis=1))\n",
    "\n",
    "# Print classification reports\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_cnn))\n",
    "\n",
    "print(\"\\nBiLSTM Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_bilstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce8b85db-5801-49c6-9f31-2a04ccec5c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 1.6437 - val_accuracy: 0.9466 - val_loss: 0.2723\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.2847 - val_accuracy: 0.9213 - val_loss: 0.2571\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.2372 - val_accuracy: 0.8707 - val_loss: 0.4560\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.2311 - val_accuracy: 0.8900 - val_loss: 0.3144\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.2013 - val_accuracy: 0.9565 - val_loss: 0.1731\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1865 - val_accuracy: 0.9512 - val_loss: 0.1720\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9532 - loss: 0.1739 - val_accuracy: 0.9526 - val_loss: 0.1702\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.1619 - val_accuracy: 0.9629 - val_loss: 0.1237\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.1464 - val_accuracy: 0.9554 - val_loss: 0.1645\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9606 - loss: 0.1397 - val_accuracy: 0.9638 - val_loss: 0.1199\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9201 - loss: 0.5270 - val_accuracy: 0.9503 - val_loss: 0.1738\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.1886 - val_accuracy: 0.9440 - val_loss: 0.2264\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9540 - loss: 0.1545 - val_accuracy: 0.9618 - val_loss: 0.1291\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9578 - loss: 0.1384 - val_accuracy: 0.9656 - val_loss: 0.1267\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.1201 - val_accuracy: 0.9655 - val_loss: 0.1089\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.1061 - val_accuracy: 0.9689 - val_loss: 0.1005\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9715 - loss: 0.0989 - val_accuracy: 0.9683 - val_loss: 0.1029\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9733 - loss: 0.0914 - val_accuracy: 0.9760 - val_loss: 0.0896\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0882 - val_accuracy: 0.9720 - val_loss: 0.0951\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0867 - val_accuracy: 0.9761 - val_loss: 0.0869\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13ms/step - accuracy: 0.9153 - loss: 0.2989 - val_accuracy: 0.9468 - val_loss: 0.1713\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 14ms/step - accuracy: 0.9465 - loss: 0.1793 - val_accuracy: 0.9415 - val_loss: 0.2029\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - accuracy: 0.9388 - loss: 0.2187 - val_accuracy: 0.9475 - val_loss: 0.1773\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9515 - loss: 0.1536 - val_accuracy: 0.9623 - val_loss: 0.1202\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.9599 - loss: 0.1266 - val_accuracy: 0.9635 - val_loss: 0.1156\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 14ms/step - accuracy: 0.9584 - loss: 0.1289 - val_accuracy: 0.9660 - val_loss: 0.1069\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 14ms/step - accuracy: 0.9638 - loss: 0.1164 - val_accuracy: 0.9540 - val_loss: 0.1376\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9649 - loss: 0.1179 - val_accuracy: 0.9645 - val_loss: 0.1136\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.9732 - loss: 0.0884 - val_accuracy: 0.9732 - val_loss: 0.0858\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9757 - loss: 0.0798 - val_accuracy: 0.9741 - val_loss: 0.0845\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "HardC Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Print classification reports\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHardC Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true_original, y_pred_hardc))\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCNN Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true_original, y_pred_cnn))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2313\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2310\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2313\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n\u001b[0;32m   2314\u001b[0m     labels_given \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:117\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(label, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ys_labels)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMix of label input types (string and number)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28msorted\u001b[39m(ys_labels))\n",
      "\u001b[1;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, LSTM, Bidirectional, SimpleRNN\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MIT-BIH Arrhythmia dataset\n",
    "# Assuming 'mitbih.csv' is your dataset file\n",
    "dataset_path = 'MITBIH.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN and LSTM\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the HardC model\n",
    "hardc_model = Sequential()\n",
    "hardc_model.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "hardc_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "hardc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the HardC model\n",
    "hardc_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the CNN model\n",
    "cnn_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Build the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "lstm_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the LSTM model\n",
    "lstm_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions using each model\n",
    "y_pred_hardc_prob = hardc_model.predict(X_test)\n",
    "y_pred_hardc = y_pred_hardc_prob.argmax(axis=1)\n",
    "\n",
    "y_pred_cnn_prob = cnn_model.predict(X_test_reshaped)\n",
    "y_pred_cnn = y_pred_cnn_prob.argmax(axis=1)\n",
    "\n",
    "y_pred_lstm_prob = lstm_model.predict(X_test_reshaped)\n",
    "y_pred_lstm = y_pred_lstm_prob.argmax(axis=1)\n",
    "\n",
    "# Convert true labels back to original labels\n",
    "y_true_original = label_encoder.inverse_transform(y_test.argmax(axis=1))\n",
    "\n",
    "# Print classification reports\n",
    "print(\"HardC Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_hardc))\n",
    "\n",
    "print(\"\\nCNN Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_cnn))\n",
    "\n",
    "print(\"\\nLSTM Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28253527-59a0-445f-a468-b15cbd6deb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.5068 - val_accuracy: 0.9483 - val_loss: 0.1659\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.1727 - val_accuracy: 0.9569 - val_loss: 0.1547\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9551 - loss: 0.1475 - val_accuracy: 0.9541 - val_loss: 0.1364\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 0.1290 - val_accuracy: 0.9682 - val_loss: 0.1114\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.1070 - val_accuracy: 0.9627 - val_loss: 0.1244\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9632 - loss: 0.1189 - val_accuracy: 0.9643 - val_loss: 0.1057\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.1035 - val_accuracy: 0.9717 - val_loss: 0.0979\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9712 - loss: 0.1006 - val_accuracy: 0.9726 - val_loss: 0.0973\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.0940 - val_accuracy: 0.9754 - val_loss: 0.0889\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.0870 - val_accuracy: 0.9692 - val_loss: 0.1018\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 21ms/step - accuracy: 0.9122 - loss: 0.6470 - val_accuracy: 0.9319 - val_loss: 0.2155\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 21ms/step - accuracy: 0.9367 - loss: 0.2172 - val_accuracy: 0.9477 - val_loss: 0.1558\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 21ms/step - accuracy: 0.9497 - loss: 0.1611 - val_accuracy: 0.9625 - val_loss: 0.1185\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 19ms/step - accuracy: 0.9622 - loss: 0.1238 - val_accuracy: 0.9709 - val_loss: 0.0984\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 22ms/step - accuracy: 0.9700 - loss: 0.0995 - val_accuracy: 0.9751 - val_loss: 0.0882\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 19ms/step - accuracy: 0.9712 - loss: 0.0971 - val_accuracy: 0.9560 - val_loss: 0.1331\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 22ms/step - accuracy: 0.9692 - loss: 0.1136 - val_accuracy: 0.9674 - val_loss: 0.1088\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 21ms/step - accuracy: 0.9735 - loss: 0.0892 - val_accuracy: 0.9782 - val_loss: 0.0757\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 21ms/step - accuracy: 0.9779 - loss: 0.0748 - val_accuracy: 0.9779 - val_loss: 0.0721\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 19ms/step - accuracy: 0.9786 - loss: 0.0719 - val_accuracy: 0.9767 - val_loss: 0.0768\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step\n",
      "CNN Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Print classification reports\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true_original, y_pred_cnn))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBiLSTM Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true_original, y_pred_bilstm))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2313\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2310\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2313\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n\u001b[0;32m   2314\u001b[0m     labels_given \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:117\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(label, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ys_labels)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMix of label input types (string and number)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28msorted\u001b[39m(ys_labels))\n",
      "\u001b[1;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, Bidirectional, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MIT-BIH Arrhythmia dataset\n",
    "# Assuming 'mitbih.csv' is your dataset file\n",
    "dataset_path = 'MITBIH.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the CNN model\n",
    "cnn_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Build the BiLSTM model\n",
    "bilstm_model = Sequential()\n",
    "bilstm_model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1))))\n",
    "bilstm_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "bilstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the BiLSTM model\n",
    "bilstm_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions using CNN model\n",
    "y_pred_cnn_prob = cnn_model.predict(X_test_reshaped)\n",
    "y_pred_cnn = np.argmax(y_pred_cnn_prob, axis=1)\n",
    "\n",
    "# Make predictions using BiLSTM model\n",
    "y_pred_bilstm_prob = bilstm_model.predict(X_test_reshaped)\n",
    "y_pred_bilstm = np.argmax(y_pred_bilstm_prob, axis=1)\n",
    "\n",
    "# Convert true labels back to original labels\n",
    "y_true_original = label_encoder.inverse_transform(y_test.argmax(axis=1))\n",
    "\n",
    "# Print classification reports\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_cnn))\n",
    "\n",
    "print(\"\\nBiLSTM Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_bilstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cad1849-de96-4375-98cb-246cf15193fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.9719 - val_accuracy: 0.9460 - val_loss: 0.1746\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9464 - loss: 0.1834 - val_accuracy: 0.9505 - val_loss: 0.1479\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9517 - loss: 0.1509 - val_accuracy: 0.9635 - val_loss: 0.1306\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1310 - val_accuracy: 0.9677 - val_loss: 0.1066\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.1153 - val_accuracy: 0.9662 - val_loss: 0.1148\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.0990 - val_accuracy: 0.9729 - val_loss: 0.0880\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9703 - loss: 0.0940 - val_accuracy: 0.9753 - val_loss: 0.0892\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9734 - loss: 0.0870 - val_accuracy: 0.9762 - val_loss: 0.0804\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0818 - val_accuracy: 0.9770 - val_loss: 0.0777\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9761 - loss: 0.0789 - val_accuracy: 0.9727 - val_loss: 0.0865\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 20ms/step - accuracy: 0.9297 - loss: 0.4259 - val_accuracy: 0.9472 - val_loss: 0.1663\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 21ms/step - accuracy: 0.9489 - loss: 0.1670 - val_accuracy: 0.9678 - val_loss: 0.1134\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 20ms/step - accuracy: 0.9618 - loss: 0.1235 - val_accuracy: 0.9716 - val_loss: 0.0931\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 20ms/step - accuracy: 0.9685 - loss: 0.1057 - val_accuracy: 0.9595 - val_loss: 0.1432\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 22ms/step - accuracy: 0.9697 - loss: 0.1077 - val_accuracy: 0.9741 - val_loss: 0.0869\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9731 - loss: 0.0929 - val_accuracy: 0.9783 - val_loss: 0.0743\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 23ms/step - accuracy: 0.9774 - loss: 0.0743 - val_accuracy: 0.9792 - val_loss: 0.0717\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 21ms/step - accuracy: 0.9774 - loss: 0.0768 - val_accuracy: 0.9739 - val_loss: 0.1113\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - accuracy: 0.9787 - loss: 0.0722 - val_accuracy: 0.9811 - val_loss: 0.0633\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - accuracy: 0.9811 - loss: 0.0645 - val_accuracy: 0.9803 - val_loss: 0.0655\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (20138, 5) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m y_pred_bilstm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_bilstm_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Convert true labels back to original labels as strings\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m y_true_original \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(y_test)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Convert predicted labels to strings\u001b[39;00m\n\u001b[0;32m     66\u001b[0m y_pred_cnn_original \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(y_pred_cnn)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:155\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform labels back to original encoding.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03m    Original encoding.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    154\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 155\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# inverse transform of empty array is empty array\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1193\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1194\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1198\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1199\u001b[0m         )\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1204\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (20138, 5) instead."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, Bidirectional, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MIT-BIH Arrhythmia dataset\n",
    "# Assuming 'mitbih.csv' is your dataset file\n",
    "dataset_path = 'MITBIH.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the CNN model\n",
    "cnn_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Build the BiLSTM model\n",
    "bilstm_model = Sequential()\n",
    "bilstm_model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1))))\n",
    "bilstm_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "bilstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the BiLSTM model\n",
    "bilstm_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions using CNN model\n",
    "y_pred_cnn_prob = cnn_model.predict(X_test_reshaped)\n",
    "y_pred_cnn = np.argmax(y_pred_cnn_prob, axis=1)\n",
    "\n",
    "# Make predictions using BiLSTM model\n",
    "y_pred_bilstm_prob = bilstm_model.predict(X_test_reshaped)\n",
    "y_pred_bilstm = np.argmax(y_pred_bilstm_prob, axis=1)\n",
    "\n",
    "# Convert true labels back to original labels as strings\n",
    "y_true_original = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Convert predicted labels to strings\n",
    "y_pred_cnn_original = label_encoder.inverse_transform(y_pred_cnn)\n",
    "y_pred_bilstm_original = label_encoder.inverse_transform(y_pred_bilstm)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_cnn_original))\n",
    "\n",
    "print(\"\\nBiLSTM Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_bilstm_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b588982-bcc4-4b59-974b-082bf9a3bd42",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert ['NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBVEBNNVEBNVEBVEBNVEBNVEBVEBNNVEBVEBNVEBVEBNNVEBVEBNNVEBVEBNVEBNVEBVEBNVEBNVEBNVEBVEBNVEBNVEBVEBNVEBNVEBVEBNVEBVEBNVEBVEBNVEBNVEBVEBNVEBNVEBVEBNVEBNNNVEBVEBNVEBVEBNVEBNNNNNVEBVEBNVEBNVEBVEBNVEBNVEBNVEBNNNNNNVEBVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNVEBNVEBNNVEBNVEBNNNNVEBNNNVEBVEBNNVEBNVEBNNNVEBNNVEBVEBNVEBNNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNVEBVEBNVEBNVEBNVEBNVEBNNNNVEBVEBNNNNVEBNVEBNVEBNNVEBVEBNVEBNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNVEBNVEBNVEBNNVEBVEBNVEBNNNVEBVEBNVEBNVEBNNNNNNNVEBNNNNNVEBNNNVEBVEBNVEBNNNVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNVEBVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNVEBVEBNVEBNVEBVEBNVEBNVEBNNVEBNNVEBVEBNVEBNVEBNVEBNNVEBVEBNVEBNNNNVEBNNNNVEBNNVEBVEBNVEBNVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNVEBNNNNVEBNNNNNNNNVEBNNNNNVEBNNVEBNNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNNVEBNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBVEBNVEBNVEBVEBNNNVEBVEBNNVEBVEBNVEBVEBNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNVEBVEBNNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNVEBVEBNNVEBVEBNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNVEBVEBNVEBVEBNVEBNVEBVEBNVEBVEBNVEBNVEBVEBNVEBNNVEBNNVEBNNVEBVEBNNVEBNVEBVEBNNVEBVEBNNVEBVEBNNNVEBVEBNNVEBVEBNNVEBNVEBNNNNVEBVEBNVEBNNNNNNVEBVEBNVEBNNVEBVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNNVEBVEBNVEBNVEBNVEBNNVEBVEBNVEBNVEBVEBNNNNVEBNNNVEBVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNVEBSVEBNNNVEBNNNNVEBNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNVEBNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNFNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNVEBNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNFNNNNNVEBNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNVEBNNNNVEBNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNFNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBSVEBSVEBSVEBVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNFNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNSVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNVEBNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNVEBNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNVEBNNVEBNNNNNNNVEBNNNVEBNNNVEBNNNNNNNNNVEBNNNNNNNVEBNNNNNNNVEBNNVEBVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNSVEBNVEBNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNSVEBNSVEBNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNSVEBNVEBNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNSVEBNSVEBNNNNNNNNNNNNNVEBNNNNSVEBNNNNNNNNNNNSVEBNNNNNSVEBNNNNNSVEBNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNNNNSVEBNNVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNSVEBNVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNVEBNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNSVEBNNNNSVEBNNNNNNNSVEBNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNVEBSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNSVEBNSVEBNVEBNNNNNVEBNNNNNVEBNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNNNNNVEBNVEBNVEBNVEBNNNNNVEBNNVEBNNVEBNVEBNNVEBNVEBNVEBNNNNNNNNNVEBNNNNNNNVEBNNNNNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNVEBNVEBNVEBNNNVEBNNVEBNNNNNVEBNNNNNNNNNNNNVEBNNVEBNNVEBNVEBNNVEBNNNNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNVEBNVEBNNNVEBNVEBNVEBNNNNNNNNNNNNVEBNNNVEBNVEBNNNVEBNVEBNNVEBNNVEBNNVEBNVEBNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNNNVEBNVEBNNNVEBNNNVEBNVEBNVEBNNVEBNNVEBNNVEBNVEBNVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNNNNNNNNVEBNVEBNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNVEBNVEBNNNNNNNNNNNNNNNVEBNVEBNNNVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNNNVEBNNNNNNNNVEBNVEBNNNVEBNVEBNVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNNVEBNNVEBNNVEBNVEBNNVEBNNVEBNNVEBNNNNNNNNVEBNNVEBNVEBNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNNNNVEBNNVEBNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNVEBNNVEBNNVEBNVEBNNNNNVEBNVEBNNNVEBNVEBNNNNNNVEBNNVEBNNVEBNNVEBNVEBNVEBNNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNVEBNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNVEBNNNVEBNVEBNNNVEBNNVEBNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNVEBNNNVEBNNNVEBNNNNVEBNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNVEBNNNNNVEBNNNNVEBNVEBNNNVEBNVEBNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNNNNNNNNNVEBNNVEBNVEBNVEBNNNVEBNNNNNNVEBNVEBNVEBNNNNNNNNVEBNVEBNVEBNNVEBNNNNVEBNVEBNVEBNNNVEBNNNNNVEBNNNNVEBNVEBNVEBNVEBNVEBNNNNNVEBNVEBNVEBNNNNVEBNVEBNVEBNVEBNVEBNNNNNVEBNNNNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNVEBNVEBNVEBNNNNVEBNVEBNNNNVEBNNNNVEBNVEBNNVEBNNNVEBNNNVEBNNVEBNVEBNNNVEBNNVEBNNVEBNNVEBNNNNNVEBNVEBNVEBNVEBNNNNNVEBNNVEBNVEBNNVEBNNNVEBNVEBNVEBNNNVEBNNNVEBNVEBNNVEBNVEBNNVEBNNVEBNNVEBNNVEBNVEBNVEBNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNVEBNVEBNNNNNVEBNNVEBNNNVEBNVEBNVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNNVEBNNVEBNVEBNNNNNNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNNNVEBNVEBNNVEBNNVEBNVEBNVEBNVEBNNVEBNNVEBNVEBNNVEBNNNVEBNVEBNNNVEBNVEBNNVEBNNNNVEBNNNNNVEBNVEBNNVEBNNNVEBNVEBNNVEBNVEBNNNVEBNVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNVEBNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNNVEBNNNVEBNVEBNVEBNNVEBNNNNNNVEBNNVEBNVEBNNNVEBNVEBNNNVEBNNNVEBNNNNVEBNNNVEBNNNNNNNNVEBNVEBNNNVEBNVEBNNNVEBNVEBNNNVEBNNNNVEBNVEBNNNVEBNNNNNVEBNVEBNNVEBNNVEBNNVEBNVEBNNVEBNVEBNNNNNNVEBNVEBNNNNVEBNVEBNNNNNVEBNNNNNNNNNNNNNNVEBNNVEBNNNNNNVEBNNNNNVEBNVEBNNVEBNNNNNVEBNNVEBNNNNNNNNNNNNVEBNVEBNNNNVEBNVEBNVEBNNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBVEBSVEBSVEBSVEBVEBSVEBSVEBSVEBSVEBSVEBSVEBFVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBFSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNFFVEBVEBVEBVEBVEBFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNNNVEBVEBVEBVEBVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNSVEBNSVEBNNNVEBNNSVEBNNNNNNSVEBNNNNNNNVEBNNNNNNSVEBNNVEBNNNNVEBSVEBSVEBNSVEBSVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNSVEBNNNNNNNNNNNSVEBNSVEBNNVEBSVEBNNNNNNNNNNNNVEBNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNSVEBNNVEBNNVEBNNNNVEBNNNNVEBNNNNVEBNNNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNVEBNSVEBNNNVEBNNVEBNNVEBNNVEBNNVEBNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNSVEBNNVEBNSVEBNNNVEBNNVEBNSVEBNNNVEBNSVEBNNNVEBNNNNNVEBNNSVEBNNNVEBNNVEBNNNSVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNSVEBNNVEBNNVEBNNVEBNNVEBNSVEBNNVEBNNVEBNNNSVEBNNVEBNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNVEBNNVEBNNVEBNSVEBSVEBNNVEBNNVEBNNVEBNNSVEBNNSVEBNSVEBNNNNNSVEBSVEBNNVEBNNNNNNNSVEBNSVEBNNNNNVEBNNNNNNNVEBSVEBSVEBNNVEBSVEBNNNVEBNNVEBSVEBSVEBNNVEBNSVEBNNVEBNNVEBNNVEBNNVEBSVEBSVEBNNNNVEBNSVEBSVEBNNVEBNNSVEBNNVEBNNVEBNNNSVEBNNVEBNNNVEBNSVEBSVEBNNNVEBSVEBSVEBNVEBNNVEBNSVEBNNVEBNNVEBSVEBNNNVEBSVEBNNNVEBNNVEBNNSVEBSVEBNNSVEBNNVEBNNNSVEBNNVEBNNNVEBNSVEBNNNVEBNNVEBNNNNVEBNSVEBNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBSVEBSVEBNNSVEBNNSVEBSVEBNNFNSVEBNSVEBNNSVEBNSVEBNNSVEBNSVEBNSVEBNNSVEBNSVEBNSVEBSVEBNSVEBNNSVEBNSVEBSVEBNSVEBNNSVEBNSVEBNSVEBNNSVEBNSVEBNNSVEBNSVEBNSVEBNNSVEBSVEBNSVEBSVEBNNNSVEBNNSVEBNNSVEBNNNVEBNNNSVEBNNSVEBSVEBNNNSVEBSVEBNSVEBSVEBNSVEBNNSVEBSVEBNSVEBSVEBNNSVEBNSVEBNFSVEBNNSVEBNNNSVEBNNSVEBSVEBSVEBNNNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNVEBVEBNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBVEBVEBNVEBNNNNNNNNNNVEBNNNNNNNNNNNVEBVEBNVEBNNNNNNVEBNVEBNNNNNNNNVEBNNNVEBVEBNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNVEBVEBVEBNVEBNSVEBNNNVEBVEBNSVEBNNNNNVEBNNNNNVEBVEBVEBNNNVEBVEBNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNVEBNNNNNVEBNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNVEBNVEBNNNVEBVEBNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBVEBNNNVEBNNNNVEBNNNNNNNNNVEBNVEBVEBVEBNNNNNNNNNNNVEBNVEBVEBNNVEBNNNNNNNVEBNVEBVEBNNNNNVEBNNNNVEBNNNNNNNNNVEBVEBVEBVEBNVEBVEBVEBVEBVEBVEBVEBVEBVEBNVEBNVEBNNVEBVEBNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNNNNNNNNNNNNVEBNNNNVEBNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNVEBVEBNNVEBNNNVEBNNNNNNNNNNNNNNNNVEBVEBNNVEBVEBNNNNNNNNNNNNNVEBNNNNVEBNNVEBNNNNVEBNNVEBNVEBNNNNNVEBNVEBNNNNNNNNNVEBNNNNVEBNNNVEBNNNNNNNNNVEBNVEBNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNVEBNNNNNNNNNVEBNNNVEBNNNVEBVEBVEBNNVEBNNNVEBNNVEBNNNNNNNNNNNVEBVEBNNNNNNNNVEBVEBNNNNNNVEBNNNNNNNNVEBNNNNNNNNVEBNNNNNNNVEBNNQNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNVEBNNNNNNVEBNNNNNNNNNNNVEBNNVEBNVEBNNNNNNVEBNVEBVEBNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNVEBNNNNVEBVEBNNNNNNNNNVEBVEBNVEBNNNNNNNNNVEBNNVEBVEBNVEBNNNNVEBNVEBNNNNNVEBNNNNNNVEBVEBVEBVEBNNNNNNNVEBNNNNNVEBNNNVEBNNNNNVEBVEBNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNVEBNNVEBVEBVEBNNNNNVEBNVEBNVEBVEBNNVEBNVEBNNNNNNNNNNNNNNNVEBVEBNNNNNNNNVEBNNNNNNNNNNNNNVEBVEBVEBVEBNVEBNNNNNNVEBVEBNNNNNNNVEBNNNVEBNNVEBNNNVEBVEBVEBVEBNNNVEBNNNNNVEBVEBNNVEBNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBVEBNNVEBVEBNNNNVEBNNNNNNNNNVEBNNNNNNNNNNVEBNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBVEBNNNNVEBNNNNNVEBNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNVEBNNNNNNVEBNNNNNNNNNVEBNVEBNNNVEBNNNNVEBNVEBNNNNNNNVEBNNNNVEBVEBNNNVEBNNNNNVEBNNNNNNNNNNNVEBNVEBNNVEBVEBNNVEBNNNVEBVEBVEBNNVEBNVEBNNNNNNVEBVEBNVEBNNNNNVEBNNNVEBNNNNNNNNNNNVEBVEBNNVEBVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBVEBNNNNNNVEBVEBVEBNNNNVEBNNNNNNNNNVEBNNNNNVEBNNNVEBNVEBNNNNNNNNVEBVEBVEBNVEBNVEBNVEBVEBVEBVEBNVEBNNNNNVEBVEBNNVEBNVEBNVEBNNNNVEBNNNNNNNNNNVEBNNNVEBNNNNNNNNNNVEBVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNVEBVEBVEBNNNNNNNNNNNNNNVEBVEBNNVEBVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNVEBNNNVEBVEBNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNVEBNNNNNVEBVEBNNNVEBNNNNNNNNNNNVEBVEBNNNNNVEBNNNVEBVEBNNNNNNNNNNNNNNNVEBNVEBVEBNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNQQQNNNNVEBNNNNVEBVEBVEBNNNVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNVEBNNVEBVEBNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBVEBNNVEBNVEBNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNVEBNNVEBNNNNNNNNVEBVEBNNNNNNNNNNNNVEBNNNVEBNNVEBVEBVEBVEBVEBVEBVEBNNNNNNNNNVEBNNNNNVEBVEBNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBVEBVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNVEBVEBNVEBNNNNNNNVEBNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBVEBVEBVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNVEBVEBNNNNNNVEBNFNNNNNVEBVEBNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNSVEBVEBVEBVEBVEBVEBVEBVEBVEBNNFVEBVEBVEBVEBVEBVEBVEBVEBVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNVEBNVEBVEBVEBNNNNNNNNNNNNNNNNNNFNNNNNFNNNNFNNNNNNNNNNNNNNNNNNNNNNFNNNNNNVEBNNNNNNNNNFNNNNNFNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBNVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBNSVEBNVEBVEBVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBVEBVEBNNVEBNNVEBVEBVEBNNNVEBNNNNNVEBNVEBNVEBNNVEBVEBNVEBVEBNNVEBNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNVEBNNNVEBVEBNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBNNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBFVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNNFNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNFNNNNNNVEBNNVEBNNFNNVEBNNVEBNNFNNNNNNVEBNNVEBNNFVEBNFVEBNNVEBNNFVEBNNVEBNNVEBNNVEBVEBNFVEBNFVEBNNVEBNNVEBNNVEBVEBNVEBVEBNFVEBNNNNNVEBVEBNVEBVEBNFVEBNNFNNNNNFVEBNFVEBNNVEBNNVEBNNFVEBNNNNNFVEBNVEBVEBNFVEBNNVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNNVEBNNVEBNNVEBNNVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNNVEBNNVEBNNVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNFVEBNFVEBNNFNNNVEBNNFVEBNNNNNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNNVEBNNVEBNFVEBNNVEBNNVEBNNNNNFVEBNFVEBNFVEBNNNNNVEBVEBNFVEBNNVEBNNFVEBNNNVEBNNNVEBNNNNNFVEBNNVEBNNNNNFVEBNVEBVEBNFVEBNNVEBNNVEBNFVEBNFVEBNNVEBNNNNNFVEBNFVEBNFVEBNNVEBNNFVEBNFVEBNNVEBNNFVEBNVEBVEBNVEBVEBNFVEBNNVEBNNVEBNNVEBNFVEBNFVEBNNVEBNNFVEBNFVEBNNVEBNNVEBVEBNVEBVEBNFVEBNNNNNVEBVEBNVEBVEBNFVEBNNVEBNNVEBNFVEBNFVEBNNVEBNNVEBNNVEBNNVEBNNFNNVEBNNNNFVEBNNVEBNNNNNFVEBNFVEBNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNVEBNNFVEBNNNNNNFNNNVEBNNNVEBNNFVEBNNNNNNVEBNNNVEBNNNVEBNNNFNNNNNNNNNNNFNNNVEBNNVEBNNVEBNNVEBNFVEBNVEBNNFVEBNNVEBNNFVEBNVEBNNFVEBNVEBNNNVEBNNFVEBNFVEBNFVEBNNFVEBNNVEBNNVEBVEBNFVEBNFVEBNNVEBNNVEBVEBNVEBNNFVEBNVEBVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNNNNNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNNFNNFVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFNNVEBVEBNVEBVEBNNNNNNNNNNNNNFVEBNFVEBNFVEBNNVEBNNFVEBNFVEBNNNNNFVEBNNVEBNFVEBNFVEBNFVEBNNVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNNVEBNNVEBNVEBVEBNFVEBNNNNNNNNNFVEBNFVEBNNNVEBNNFNNFVEBNNNVEBNNFVEBNVEBVEBNNVEBNNFVEBNFVEBNNVEBNNVEBNNFVEBNFVEBNFVEBNNVEBNNVEBNNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBVEBNVEBNNFVEBNVEBVEBNVEBNNFVEBNNVEBNNFVEBNNNNNVEBVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNVEBNNVEBNNVEBNNVEBNVEBVEBNVEBVEBNNFVEBNVEBVEBNVEBNNFNNVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBNNVEBNNVEBNNVEBNNVEBNNFVEBNNVEBNFVEBVEBNNNVEBVEBNNFVEBNVEBVEBNVEBNNFVEBNVEBVEBNVEBVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNFVEBVEBNNFVEBVEBNNFVEBNVEBVEBNFVEBNNFVEBNFVEBNVEBNNVEBVEBNNVEBNNVEBNSVEBVEBVEBNSVEBFVEBNVEBNNVEBNNVEBNNVEBVEBNNVEBNNVEBNNVEBNNVEBVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBVEBNVEBNNVEBNNVEBNFVEBVEBNNVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFFNFFNFNNNNNNNNFNNFNNNNNFNNNNNNNNNNNNNNFNNNNNFNNFNNFNNNNNNVEBNNVEBNNFNNNFNNVEBNNFNNFNNFNNNVEBNNFNNNNNNNFNNNNVEBNVEBNNFNNFNNVEBNNVEBNNVEBNNVEBNNVEBNNQNNFNNFVEBNNVEBVEBNVEBNNNQNNFNNVEBNNVEBNNFNNFNNVEBNNNNNVEBNNVEBNNFNNNNNNNNNNNNNNFNNFNNFNNNFNNNNNNVEBNNVEBVEBNNNNNVEBNVEBNFVEBNVEBNNVEBNNNNNVEBVEBNVEBNNNNNNFNNVEBNVEBNNFNNVEBNVEBNNFNNVEBNNVEBVEBNVEBNNVEBNNVEBNNVEBNVEBNNFNNNNNNNNNNNFNNNFNNFNNNVEBNNVEBNNVEBNVEBNNVEBNNFNNVEBNVEBNNVEBVEBNVEBNNVEBNNFNNVEBNNVEBNNVEBNNVEBNNFNNVEBNFVEBNNVEBNNVEBNNVEBVEBNVEBNNNVEBNNFNNNVEBNNFNNNVEBNNVEBNNFVEBNFNNVEBNNVEBNNFNNFVEBNVEBNNVEBNNVEBNNFNNVEBVEBNVEBNNFNNVEBNNVEBNNVEBNNVEBNNVEBVEBNFNNVEBNNFNNFNNNVEBNNVEBNFVEBNVEBNNNVEBNNVEBNFVEBNNVEBNNFNNVEBNNVEBNNVEBVEBNVEBNNNFNNFNNVEBNVEBNNFNNFNNVEBNNVEBNNFNNFNNFVEBNFVEBNNVEBNNVEBNNVEBNFVEBNFNNNVEBNFVEBNNVEBNNFVEBNNNNNNNNFNNNVEBNNFNNFVEBNNVEBNNFNNFVEBNVEBNNFNNVEBNNFNNVEBNNNVEBNNFNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBVEBNVEBNNVEBNNVEBNNVEBVEBNNNVEBVEBNNVEBNNVEBNVEBVEBNVEBNNVEBNNVEBNVEBVEBNVEBNFVEBNVEBNNVEBNNVEBNVEBNNVEBVEBNNVEBNNVEBVEBNNVEBNFVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNFNNFNNFNNVEBNFVEBNVEBNVEBVEBNVEBNFVEBNVEBNNVEBVEBNVEBNVEBVEBNNNFVEBVEBNNVEBNVEBNVEBVEBNVEBVEBNVEBNNVEBNNVEBVEBNNVEBNVEBNVEBVEBNVEBNVEBNNVEBNNVEBVEBNNVEBNVEBVEBNVEBNFVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBVEBNVEBNNVEBNNVEBNVEBVEBNVEBNVEBVEBNVEBNNFVEBNVEBVEBNVEBNVEBVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBNVEBNNVEBNNVEBVEBNVEBNFVEBVEBNNFVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNFVEBNVEBNFVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNSVEBNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNSVEBNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNVEBNNNNNNNNNNNNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNSVEBNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBVEBNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNVEBNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNVEBVEBVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNVEBNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNVEBVEBNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBFVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBSVEBSVEBNNSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBNNNSVEBNNNNNNNNSVEBSVEBSVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNSVEBSVEBNNNSVEBNNNNNNNSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNSVEBNNNNSVEBNNNSVEBSVEBSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNSVEBSVEBNNNSVEBSVEBNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNSVEBNNNSVEBSVEBNNNSVEBSVEBSVEBSVEBNNSVEBSVEBNNNSVEBSVEBNNNNNNNSVEBSVEBNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNSVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBVEBNNNFNNNFNNNFNNNFNNNFNNNFNNNNNNNNNVEBNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNSVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNSVEBNNNNNNSVEBNNSVEBNNNNNNSVEBNNNNSVEBNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNSVEBNNNNNNNNNVEBNNNNNNNSVEBNNSVEBNNNSVEBNNFNVEBNVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBNSVEBSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNSVEBSVEBNNNNNVEBNVEBNFNFNFNFNVEBNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNNVEBNVEBNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNSVEBNVEBVEBNNNNNNNNNNNNNSVEBNVEBVEBNNSVEBSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBVEBNVEBVEBVEBNVEBNVEBNVEBVEBNNNNVEBNNNNNNVEBNNNNVEBNNFNNNNVEBNNVEBNNVEBNSVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNFNVEBNVEBNVEBNSVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBVEBNVEBNVEBNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNVEBVEBNNNNSVEBNVEBVEBNNNNNNNNNNNNNNNNVEBNNNNFNSVEBNVEBVEBNNVEBNNVEBNNNNNNNVEBNNVEBNNVEBNVEBVEBNVEBVEBNNNNNNNNNNVEBNNVEBNNVEBNVEBVEBNVEBNVEBVEBVEBVEBVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNNNNNNNNNNSVEBNVEBVEBNNNSVEBNNNNNNNNSVEBNVEBVEBNVEBVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNSVEBNNNNNSVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNVEBVEBNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNSVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQNNNNQNNNNNNNNNNQNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNVEBNVEBNVEBVEBNVEBNVEBVEBNVEBNNNNNNNNNNNVEBNVEBVEBNVEBNNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNSVEBNNNNNNNVEBNVEBNVEBNVEBNVEBNNNVEBNVEBNVEBNVEBNVEBVEBNVEBNNNNNNNNNNSVEBNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNVEBNNNVEBNVEBNNNNNVEBNNNVEBNVEBNNNNNNNVEBVEBNNNNVEBNNNVEBNVEBNNNNNNNNNNNVEBNVEBNNNNNVEBNVEBNNNNNNNNNVEBNNNNNVEBNNNVEBNVEBNNNNNNNVEBNVEBNVEBNVEBNNNVEBNNNVEBNVEBNVEBNVEBNNNVEBNVEBNNNNNVEBNVEBNNNVEBNVEBNNNNNVEBNNNNNVEBNVEBNNNNNNNVEBNVEBNVEBNVEBNNNNNNNNNNNVEBNVEBNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNNNNNNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNSVEBVEBNVEBNNNNNNNNVEBNVEBNVEBNVEBNVEBNNNNNNVEBNVEBNVEBNVEBVEBNVEBNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNVEBNNVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNNNNNNSVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBVEBNVEBNNFNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNSVEBNVEBNVEBVEBVEBNVEBNVEBNNNNNNNNNVEBNVEBNVEBNVEBNNNVEBNVEBNVEBVEBNVEBNNNVEBNVEBNNNVEBNVEBNNNVEBVEBNNNVEBNVEBNNNVEBNNNVEBNNNVEBNVEBNNNVEBNVEBNNNVEBNVEBNNNVEBNVEBNNNVEBNVEBNNNNNNNNNVEBNVEBNNNNNNNNNNNNSVEBNVEBNVEBNVEBNNNVEBNVEBNVEBNNNVEBNVEBNNNSVEBNVEBNVEBNNNNNVEBNVEBNNNNNNNNNNNNNVEBNVEBNVEBNSVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNVEBNVEBNVEBNNNNNSVEBNVEBNVEBNVEBNVEBNVEBNNNVEBNVEBNVEBNVEBNNNVEBNVEBVEBNVEBNNNNNNNVEBNVEBNVEBNNNVEBNVEBNNNNNNNNNNNVEBNVEBNNNVEBVEBNNNNNNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNVEBNNNVEBNNNNNNNVEBNNNNNNNNNNNVEBNVEBNVEBNNNNNNNNVEBVEBVEBVEBNNNNVEBNVEBNNNNNNNNNVEBNVEBNVEBNVEBNVEBNSVEBNVEBNVEBNVEBNVEBNVEBNSVEBNVEBNVEBNVEBNVEBVEBNNNNNNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNNNNNNNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNNNNSVEBNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBFNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBVEBVEBVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNVEBVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNNNNNNNNVEBNVEBVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNNNNNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNSVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNSVEBNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBVEBNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNNVEBNNNNNNNNNNNNNSVEBNVEBNVEBVEBVEBNVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNNNNSVEBNNNNNVEBNVEBNVEBNNNNNNSVEBSVEBNVEBVEBNVEBNNVEBNVEBNNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNNVEBNVEBNVEBNNNNNNNNNNNNSVEBNVEBNVEBNVEBNVEBVEBNVEBVEBNNNNNNNVEBNVEBNVEBNNNVEBNVEBNVEBNVEBNNNNNNNNNSVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNSVEBNVEBNVEBNNVEBNVEBNNNNVEBVEBNVEBNVEBNVEBNNNNNNNNSVEBNVEBNVEBNVEBNNNNNNNNNNNNNNSVEBNVEBNVEBNVEBNNNNVEBNVEBNVEBNVEBNNNSVEBNVEBNVEBNNVEBVEBNVEBNNNNNVEBNVEBNNNNNSVEBNVEBNVEBNNNNNNNNNNNNNNNVEBNVEBNNVEBNNVEBNVEBNNVEBVEBNVEBNNNNNNNNSVEBNNNNNNNVEBNVEBNNNNNVEBNVEBNVEBNNNSVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNSVEBNVEBNNNNNVEBNVEBNVEBNVEBNNNNNNNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNVEBNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBSVEBNNNNNNSVEBNNSVEBNNSVEBNNNVEBNNNNSVEBNNSVEBNNSVEBVEBNNNSVEBNNNSVEBNNNNNSVEBNNNSVEBNNSVEBNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBSVEBNSVEBNSVEBNSVEBNSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBNSVEBNSVEBSVEBNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBFSVEBSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNFNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNVEBNNVEBNVEBNNVEBNNVEBVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBVEBVEBVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNFNNNNNNNNNNNNFNNVEBNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBVEBNNNNVEBNNNNNNNNNNNNNSVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNVEBSVEBNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBVEBNNNNVEBVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNVEBNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNSVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNVEBNNNNNNFNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBFNNVEBNVEBVEBVEBVEBVEBVEBNVEBNVEBNNNVEBNVEBNVEBNFNNNVEBNNNFNNVEBNVEBNVEBNVEBVEBNVEBVEBNVEBNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBVEBNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNSVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNSVEBVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNSVEBNVEBNNNSVEBSVEBNNNNNNNNNSVEBNNNNNNNNNNNNNNNNVEBNVEBNVEBNNNVEBNVEBNNVEBNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNVEBNVEBNSVEBVEBVEBVEBFNNNVEBNNNNNVEBNVEBNNNNNVEBNNNNNNNNNNNVEBNNNVEBNVEBNNNSVEBVEBNVEBNNNNNNNNNNVEBNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNFNFNFNVEBNFNFNFNNNFNFNFNFNFNFNFNFNFNFNFNVEBNFNFNFNNNNNNNNNFNFNVEBNVEBNVEBNFNNNFNFNFNFNVEBNFNFNFNFNFNFNVEBNVEBNFNFNNNNNNNFNVEBNNNFNFNFNFNFNFNNNNNFNVEBNVEBNFNFNFNFNNNNNFNVEBNVEBNFNFNFNFNFNFNFNFNFNFNVEBNFNNNNNFNVEBNFNFNFNFNFNFNFNFFNNNNFNFNFNFNFNFNFNFNFNNNNNNNFNVEBNFNNNNNNNFNFNVEBNNNNNNNNNFNFNFNVEBNNNNNNNNNNNNNVEBNVEBNVEBNFNNNFNNNNNNNFNVEBNNNNNNNNNFNVEBNNNNNNNNNNNNNNNNNFNVEBNVEBNFNNNNNFNVEBNVEBNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNVEBNVEBNVEBNNNNNNNFNVEBNVEBNNNNNNNNNNNFNVEBNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNSVEBNNNNNNVEBNNNNNNNNNNNFNVEBNVEBNFNFNFNFNFNVEBNVEBNFNFNFNVEBNVEBNVEBNFNFNVEBNNNVEBNFNVEBNVEBNVEBNFNFNFNFNVEBNVEBNVEBNNNNNFNFNFNVEBNVEBNVEBNFNFNFNFNFNVEBNVEBNFNNNNNNNVEBNVEBNNNNNNNNNSVEBNVEBNNNFNFNVEBNFNFNFNVEBNVEBNFNFNFNFNFNFNFNFNVEBNFNVEBNFNFNFNFNVEBNFNFNNNNNNNFNFNVEBNFNNNNSVEBNNNNFNVEBNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNVEBNNNVEBNFNFNFNFNFNFNFNFNFNNNFNFNFNFNFNNNFNFNFNFNFNFNFNFNFNFNNNNNNNNFNNVEBNVEBNVEBNFNNNNNNNNNVEBNNNNNNNNNFNVEBNVEBNVEBNNNNNNNNNFNVEBNVEBNFSVEBNNNNNNNNVEBNFNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNFNVEBNVEBNFNFNFNFNVEBNVEBNVEBNVEBNFNFNFNFNFNFNFNVEBNVEBNVEBNFNNNNNNNFNVEBNVEBNVEBNVEBNVEBNNNNNNNNNFNVEBNNNNNNNFNVEBNNNVEBNVEBNFNFNFNFNFNVEBNVEBNFNFNNNNNFNVEBNVEBNFNFNFNFNFNVEBNFNFNNNNNNNNNFNNNFNNNNNSVEBNVEBNNNNNNNNNFNVEBNVEBNVEBNNNNNNNNNFNVEBNVEBNNNNNNNNNNNFNNNVEBNNNNNVEBNNNNNNNNNSVEBVEBNNNNFNFNNNNNNNNNFNVEBVEBFNNNNNNNFNVEBNNNNNNNNNNFVEBNFNNNNNNNNNVEBNFNFNNNNNNNSVEBNVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNFNFNVEBNVEBNVEBNVEBNFNFNFNFVEBVEBVEBVEBNFNNNFNVEBNVEBNVEBNFNFNFNVEBNFNVEBNFNFNVEBNVEBNVEBNVEBNVEBNVEBNFNVEBSVEBVEBNNFNVEBNNNNNNNNNNNFNVEBNNNNNNNNNNNFNNNVEBNVEBNFNFNFNNNNNNNFNFNNNNNNNNNNNFNVEBNVEBNFNNNNNNNNNVEBNNNVEBNFNFNFNFNFNFNVEBNFNNNNNNNNNNNFNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNFNVEBNFNFNFNFNNNNNFNFNFNNNNNNNFNVEBNFNFNFNFNVEBNNNNNNNNNFNVEBNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNFNFNFNFNFNFNFNVEBNNNFNFNVEBNFNVEBNFNVEBNFNFNFNFNFNVEBNFNVEBNFNFNFNFNFNVEBNFNNNNNNNFNVEBNNNNNFNNNNNNNNNFNVEBNNNVEBNVEBNVEBNFNNNNNNNNNVEBNVEBNVEBNFNNNNNNNNNNNFNVEBFVEBNNFFNFNFNFNVEBNFNNNNNNNFNVEBNNNNNNNFNFNVEBNFNNNFNNNFFVEBNFNFNNNNNNNFNNNFNFNVEBSVEBNNNNNNNNFNVEBNNNNNNNNNNNNNVEBNNNFNFNSVEBNVEBNFNFNNNNNNNNNNNNNFNNNNNNNNNNNNNFNNNFNNNNNNNNNNNFNVEBNSVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNFNVEBNVEBNVEBNNNFNFNFNFNVEBNFNFNFNVEBNVEBNFNVEBNVEBNVEBVEBNNNNNNVEBNNNVEBNNNNNNNNVEBNNNVEBNNNNNNVEBNNNNNNVEBNNNNNNNNFNNNNNVEBNNNVEBNFNFNFNFNNNSVEBNFNNNNNNNNNNNNNNNVEBNNNVEBNFNNNNNNNNNNNVEBNVEBNNNNNNNNNFNVEBNNNVEBNNNNNNNNNNNFNVEBNNNVEBNNNNNNNNNFNFNVEBNVEBNFNNNNNNNNNFNFNVEBNNNNNNNNNNNFNVEBNFNNNNNNNNNNNNNNNFNFNVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNVEBNVEBNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNVEBNFNFNNNNNNNNNNNNNFNVEBNFNNNNNNNNNNNNNNNNNFNNNNSVEBNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNNVEBNNNVEBVEBNNNNNNNNVEBNNNVEBNNVEBNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNVEBNNNNNNVEBNNNVEBNNNNVEBNNNNNVEBNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNNNNNNNNVEBNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNVEBNNNNNNNNNNNNNNNNVEBQQNNNNNVEBNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNVEBVEBVEBNNNNNVEBNNVEBNNVEBNNNNNNVEBNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNVEBNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNVEBNNNNNNVEBNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNVEBNNVEBNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNVEBNNNNNNNNNNNNNNNVEBNNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNVEBNNNVEBNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNVEBNNVEBNNNNNNVEBNNNNNVEBNNNNNNNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNVEBNNNNNVEBNNNNVEBNNNNNNNVEBVEBVEBNNNNNVEBNNNNNNNNNNVEBVEBNNNNNNVEBNNNNVEBNNNNNNNNNNVEBNNNNNNNVEBNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNVEBNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNVEBNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNVEBNNNNNVEBNNVEBNNVEBNNNNNVEBNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNVEBNNNNNNVEBNNNVEBNNNNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNVEBNVEBNNNNNVEBNNNNNNNNNNNNVEBNNNNVEBNNVEBNNVEBNNNNNVEBNNNNNVEBVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNVEBNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNVEBNNNVEBNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNVEBNNVEBNNNNNNNNVEBNNVEBNNNNNVEBNNNNNNNNNNNNNNVEBNNVEBNNNNNNNVEBNNNVEBNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBFNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNVEBNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNSVEBNNNNNNNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNVEBNVEBNVEBNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNVEBNNVEBNNNVEBNNNNNNNNNVEBNNNVEBNNNVEBNNNNNNNNNNVEBNNNVEBNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNVEBNNNNNNNNNVEBNNNVEBNNNVEBNNNNVEBNNNNVEBNNNNNNNNVEBNNVEBNNNNVEBNNNNNVEBNNNVEBNNNNNNNVEBNNNVEBNNNNVEBNNVEBNNNNNNVEBNNVEBNNNVEBNNNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNNNNNNVEBNNNNNNNNNVEBNNNVEBNNNNNNNVEBVEBNVEBNNVEBNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNVEBNNNNVEBNNNVEBNNNVEBNNNNNNVEBNNNVEBNNNVEBNNNNVEBNNNNVEBNNVEBNNNNVEBNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNVEBNNNNNNNNNNNNVEBNNNVEBNNNVEBNNNNNNVEBNNNNVEBNNNNVEBNNNNNVEBNNVEBNNNNVEBNNVEBNNNVEBNNVEBNNVEBNNNNVEBNNNVEBNNVEBNNNNVEBNNNNNVEBNNVEBNNNVEBNNNNNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNVEBNNNNVEBNNNVEBNNNNNNNNVEBNNVEBNNNNNVEBNNNNVEBNNNNVEBNNNVEBNNNVEBNNVEBNNNNNNNNNVEBNNNVEBNNNNVEBNNNNVEBNNVEBNNVEBNNNNNNVEBNNNNNNVEBNNVEBNNNVEBNNNVEBNNVEBNNNNVEBNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNVEBNNNVEBNNNVEBNNNNVEBNNVEBNNNNVEBNNNVEBNNNNNNVEBNNNVEBNNNNNNNVEBNNNNNNVEBNNVEBNNNNNNNNNNNVEBNNNNNNVEBNNNVEBNNNNVEBNNVEBNNNNNNNNVEBNNNVEBNNVEBNNNNVEBNNNVEBNNNVEBNNVEBNNNVEBNNNNNVEBNNNNNNVEBNNNVEBNNVEBNNVEBNNNNNNNVEBNNNVEBNNVEBNNNNVEBNNNVEBNNNNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNNVEBNNNVEBNNNVEBNNVEBNNNNNNVEBNNNVEBNNNVEBNNNNNNVEBNNNNVEBNNNNVEBNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNVEBNNNVEBNNNNNNVEBNNVEBNNNNVEBNNNVEBNNNNNNVEBNNVEBNNNNVEBNNVEBNNNNNNVEBNNNVEBNNNNNVEBNNVEBNNVEBNNNNVEBNNNNVEBNNNNNNVEBNNVEBNNVEBNNNNVEBNNVEBNNNNNNNVEBNNNNNVEBNNNVEBNNVEBNNVEBNNNVEBNNNVEBNNNNVEBNNNNNNNNNNNNNVEBNNNVEBNNNVEBNNNNNVEBNVEBNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNNNNNVEBVEBVEBNNNNVEBNNNNNNNNNVEBNNNNNVEBNNVEBNNNNNNVEBNVEBNNNNNVEBNNNNVEBNNNNNVEBNNNNNNNNVEBNNNVEBNNVEBNNNVEBNNNVEBVEBVEBNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNVEBNNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNNNVEBNNVEBNNNNNNVEBNNVEBNNNNVEBNNNNNNNNVEBNNVEBNNNVEBNNNNNNVEBNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNVEBNNNNNVEBNNNNVEBNNNVEBNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNVEBNNNVEBNNNNNVEBNNNVEBNNNNNNVEBNNVEBNNNVEBNNNNVEBNNNNVEBNNNNVEBNNVEBNNVEBNNNVEBNNVEBNVEBNNNVEBNNNVEBNNVEBNNNNVEBNNVEBNNNNNVEBNNNNVEBNNNNVEBNNNNVEBNNNVEBNNNVEBNNNVEBNNNNNVEBNNNNNNVEBNNNVEBVEBNVEBNNNNNNVEBNNNVEBNNNVEBNNNVEBNNNNNVEBNNNVEBNNNNNNNNVEBNNNNVEBNNNVEBNNNNNNNVEBNNNNVEBNNVEBNNNVEBNNNVEBNNNNNVEBNNNVEBNNVEBNNNVEBNNNVEBNNVEBNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNVEBNNNNVEBNNNVEBNNNNVEBNNVEBNNNVEBNNNNNVEBNNNNNNNNNNVEBNNNVEBNNNNNVEBNNNNNNNNNNVEBNVEBNNNVEBNNNNNVEBNNNNVEBNNVEBNNNVEBNNNNNNVEBNNVEBNNNNNNNVEBNNNVEBNNVEBVEBNNNVEBNNVEBNNNNNNNNNVEBNNNVEBNNNNVEBNNNNNNVEBNNVEBNNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNNNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNVEBNVEBNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNVEBNNNNVEBNNNNNVEBNNNNNNNNNVEBNNVEBNNNVEBNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNVEBNNNVEBNNNNNNNVEBNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNVEBNNNNNNNNVEBNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNNNSVEBNNSVEBNSVEBNSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNNSVEBNNSVEBNNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNSVEBSVEBSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNSVEBNSVEBSVEBNSVEBNNNNNNNNNNNNNNNNNNSVEBNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNNSVEBNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNSVEBNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBNNNNNNNNNNSVEBNSVEBSVEBNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNSVEBNNSVEBNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNSVEBNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNNNNSVEBNNNNNSVEBNSVEBNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNNNSVEBSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNNNNSVEBNSVEBSVEBNSVEBSVEBNSVEBNNNNNNNNNNNNNSVEBSVEBNSVEBNNSVEBSVEBNSVEBNNNNNNNNNNNNNNNNNNNNSVEBNSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNSVEBSVEBNNSVEBNNNNNNNNSVEBSVEBSVEBSVEBNNNNNSVEBSVEBNNSVEBSVEBSVEBNNNNNNNNSVEBNSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNSVEBSVEBNSVEBNSVEBNNNSVEBNNNNNNNSVEBNNNNNNNNSVEBSVEBNSVEBNNNNNNNNNNNSVEBSVEBNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNVEBVEBNNNNNNNVEBNNNVEBNVEBNNNNNNNNNNNNNNNNVEBNNNNNNVEBNVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNVEBNVEBNVEBNNNNNNNNNNNNNVEBNVEBNVEBNNNVEBNNNNNVEBNNNNVEBNNNVEBNNNNNVEBNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNVEBNVEBNNNVEBNNNNNNNNVEBNVEBNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNVEBNNNNNVEBNVEBNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNVEBNVEBNNNNNNVEBNNNVEBNVEBNNNNNNNNVEBNNNNVEBNNNNVEBNNNNNNNNVEBNVEBNNNNVEBNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNVEBNVEBNVEBNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNVEBNVEBNVEBNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNVEBNNNNNNNVEBNNNNNNNNVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNVEBNNNVEBNNNNNNNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNNNVEBNNNNNVEBNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNVEBNVEBNVEBNNNNNVEBNNNNNNVEBNVEBNVEBNNNNNNVEBNNNVEBNNNNNNVEBNVEBNVEBNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNVEBNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNVEBNNNNNNNVEBNNNNNVEBNNNVEBNVEBNNVEBNNSVEBNNNNNNVEBNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNNVEBNVEBNNNNNNNNNNNNVEBNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNVEBNVEBNNNNNVEBNVEBNVEBNVEBNVEBNVEBNNNNNVEBNVEBNNNNVEBNNNNNNNNNNNVEBNVEBNNNNNNVEBNNNNNNNNVEBNVEBNNNNVEBNVEBNNNNSVEBNVEBNNNNVEBNVEBNVEBNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNVEBNNNNNNNNNNNNVEBNNNNVEBNVEBNNNNNVEBNVEBNVEBNNNNNNVEBNNNNNNVEBNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNSVEBSVEBNSVEBNSVEBNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBNSVEBNSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBVEBNVEBNNVEBNVEBNNVEBNNNVEBNNNNNNVEBNVEBNNSVEBVEBNNNNNNNSVEBNNVEBNNNVEBNNNNVEBVEBVEBNVEBNNVEBNVEBNNVEBNVEBNNNVEBNNVEBNVEBNNNVEBVEBNVEBNNNNNVEBNNNVEBNNNNNVEBNNNVEBNNVEBNNNNNNVEBNVEBNNVEBNVEBNNNNNVEBNNVEBNVEBNNVEBNNNVEBNNNVEBNNVEBNNVEBNNNNNNNNNNNVEBNNNNNVEBNNNVEBNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNVEBNNVEBNSVEBNNVEBNVEBNVEBNVEBNNNVEBNNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNVEBNNVEBNFVEBNNNVEBNNVEBNNVEBNVEBNNNNNNVEBNVEBNNNVEBNNNVEBNNNNNNVEBNVEBNNVEBNVEBNNVEBNVEBNNNVEBNNNVEBNNVEBNVEBNNNNNNNNNNVEBNVEBNNVEBNVEBNVEBNNNNNNNNVEBVEBNNVEBFNVEBFNNNVEBVEBNNNNNNNNVEBVEBNNNNVEBNNNNNNNVEBNVEBNNVEBNVEBNNNNNNNNNNNNNNNVEBNFNNNVEBVEBNVEBNNNNNVEBNNVEBNNNNNVEBNNNNNVEBNNNNNNVEBNNNVEBNVEBNNNFNNNNVEBNNNVEBNVEBNNNNNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNVEBNVEBNVEBNNNNNVEBNNNVEBNVEBNVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNVEBVEBNNNNNVEBNNNVEBNNNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNVEBNNNNVEBNVEBVEBNVEBNVEBNNVEBNVEBNNNVEBNNVEBVEBNVEBNNNVEBNNNNVEBNNNVEBVEBNVEBNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNVEBNNNNNVEBNFNNNVEBFNNNNNVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNVEBNNNVEBNNNVEBNNNVEBNVEBNNNVEBNNNVEBVEBNNNNNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNNNNNVEBNVEBVEBNNNVEBNNNVEBNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBVEBNVEBNNNNNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNVEBNNNNNNVEBVEBNVEBNNNVEBVEBNNNNNVEBNVEBVEBNVEBNVEBNVEBNVEBNNNVEBNFNNNNNNNVEBVEBNVEBNVEBNNVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNNNNNNNVEBNNVEBNVEBNNVEBNNNNNNNVEBNNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNNVEBNVEBNNNVEBNNNNNNVEBNVEBNNNVEBVEBNVEBNNVEBNNNNNVEBNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNNVEBNVEBNNVEBNNNVEBNNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNNNVEBNNNVEBNNVEBNNNNNNNVEBNNVEBNVEBNNVEBNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNNNVEBVEBNNNNNVEBNNNVEBNNNNNVEBNNNNNNNNNNVEBNNNNNNNVEBNVEBNVEBNNNVEBNNVEBNNNNNNNVEBNNVEBNNNNNVEBNNNVEBNNNVEBNVEBNVEBNNVEBVEBNNNVEBNNNNNVEBNNNNNNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNNNVEBNFVEBNVEBNVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNVEBNNNVEBNNNVEBNNVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNNNVEBNNVEBNVEBNNVEBNVEBNNNNNNNNNNNNNNNNVEBNNNVEBNVEBNNNVEBNVEBNNNNNVEBNVEBNNNNNNNNNNNNVEBNNNVEBNNNVEBNNNNNNNFNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNVEBNVEBVEBNNNNNNNNNNNNNNNVEBNVEBNNNNVEBNVEBNNVEBNVEBVEBNNNVEBNVEBNNVEBNVEBNNVEBNVEBNNNNNVEBNVEBNVEBNNNVEBNNNVEBNNVEBNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNVEBNNNNNVEBNVEBNNNNNVEBNNNSVEBNNVEBNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNVEBNVEBNNVEBNVEBNNVEBNVEBNNVEBNVEBNNNNNVEBNNNVEBNNNNNVEBNNNNNVEBNVEBNNNNNNNNVEBNVEBNNNVEBVEBNVEBNNNNNVEBNNNSVEBNNNVEBNNNVEBNNNVEBNNSVEBNNNNNNVEBNNNVEBNNVEBNNNVEBNVEBNVEBNNNNNVEBNNNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNVEBNNNNVEBVEBNVEBNVEBNNVEBNVEBNNNNNNVEBNVEBNNNNNVEBNNNNNVEBVEBNVEBNNNNNNVEBNVEBNNNVEBVEBNVEBNNVEBNVEBNNVEBNVEBVEBNNNVEBNNVEBNVEBNNVEBNVEBNVEBNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNVEBNNNNVEBNNNVEBNNNNNVEBNNNVEBNNNVEBNVEBNNNNVEBNNNVEBNNNVEBNVEBNNNVEBVEBNVEBVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNVEBNNNVEBNNNVEBNNNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNNNVEBVEBNVEBNNNNNVEBNNNVEBVEBNVEBNVEBNNNVEBNNNVEBVEBNNNNVEBVEBNNVEBNNVEBVEBVEBNVEBVEBNVEBVEBVEBNVEBNNNNVEBNVEBVEBNNNVEBNNVEBNNNVEBNNNVEBVEBVEBNNNVEBNVEBNNNNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNVEBNNNNNNNNNVEBNNNVEBNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNVEBNVEBVEBNNNVEBNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBVEBNNVEBNVEBNNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNVEBNVEBNNNNNNNNVEBNVEBVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNVEBNNNFNNNVEBNVEBVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNVEBNVEBNVEBNVEBNNNNNVEBVEBNNNVEBNVEBNNNVEBNNVEBNNVEBNVEBNNVEBNNNVEBNNNVEBNSVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNVEBNVEBNNNVEBVEBVEBNVEBNNNNNVEBNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNVEBNNVEBNVEBNNVEBNVEBNNNNVEBNNNNNNNVEBNNNVEBVEBNVEBNNVEBNVEBNVEBNVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN'] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(dataset_path)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Impute missing values with mean\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m df\u001b[38;5;241m.\u001b[39mfillna(df\u001b[38;5;241m.\u001b[39mmean(), inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Extract features and target variable\u001b[39;00m\n\u001b[0;32m     17\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11335\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11327\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11329\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11333\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11334\u001b[0m ):\n\u001b[1;32m> 11335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmean(axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  11336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11337\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11992\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11985\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11986\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11987\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11990\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11991\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11994\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11949\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11945\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  11947\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11950\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11951\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11204\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11200\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11202\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11203\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11204\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  11205\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1459\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1457\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1459\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[0;32m   1460\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1462\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:377\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 377\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    380\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11136\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[1;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    723\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1678\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1675\u001b[0m inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(x)\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1677\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[1;32m-> 1678\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1680\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mcomplex128)\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert ['NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBVEBNNVEBNVEBVEBNVEBNVEBVEBNNVEBVEBNVEBVEBNNVEBVEBNNVEBVEBNVEBNVEBVEBNVEBNVEBNVEBVEBNVEBNVEBVEBNVEBNVEBVEBNVEBVEBNVEBVEBNVEBNVEBVEBNVEBNVEBVEBNVEBNNNVEBVEBNVEBVEBNVEBNNNNNVEBVEBNVEBNVEBVEBNVEBNVEBNVEBNNNNNNVEBVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNVEBNVEBNNVEBNVEBNNNNVEBNNNVEBVEBNNVEBNVEBNNNVEBNNVEBVEBNVEBNNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNVEBVEBNVEBNVEBNVEBNVEBNNNNVEBVEBNNNNVEBNVEBNVEBNNVEBVEBNVEBNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNVEBNVEBNVEBNNVEBVEBNVEBNNNVEBVEBNVEBNVEBNNNNNNNVEBNNNNNVEBNNNVEBVEBNVEBNNNVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNVEBVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNVEBVEBNVEBNVEBVEBNVEBNVEBNNVEBNNVEBVEBNVEBNVEBNVEBNNVEBVEBNVEBNNNNVEBNNNNVEBNNVEBVEBNVEBNVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNVEBNNNNVEBNNNNNNNNVEBNNNNNVEBNNVEBNNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNNVEBNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBVEBNVEBNVEBVEBNNNVEBVEBNNVEBVEBNVEBVEBNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNVEBVEBNNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNVEBVEBNNVEBVEBNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNNVEBVEBNVEBVEBNVEBVEBNVEBNVEBVEBNVEBVEBNVEBNVEBVEBNVEBNNVEBNNVEBNNVEBVEBNNVEBNVEBVEBNNVEBVEBNNVEBVEBNNNVEBVEBNNVEBVEBNNVEBNVEBNNNNVEBVEBNVEBNNNNNNVEBVEBNVEBNNVEBVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNNVEBVEBNVEBNVEBNVEBNNVEBVEBNVEBNVEBVEBNNNNVEBNNNVEBVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNVEBSVEBNNNVEBNNNNVEBNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNVEBNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNFNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNVEBNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNFNNNNNVEBNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNVEBNNNNVEBNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNFNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBSVEBSVEBSVEBVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNFNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNSVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNVEBNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNVEBNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNVEBNNVEBNNNNNNNVEBNNNVEBNNNVEBNNNNNNNNNVEBNNNNNNNVEBNNNNNNNVEBNNVEBVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNSVEBNVEBNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNSVEBNSVEBNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNSVEBNVEBNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNSVEBNSVEBNNNNNNNNNNNNNVEBNNNNSVEBNNNNNNNNNNNSVEBNNNNNSVEBNNNNNSVEBNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNNNNSVEBNNVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNSVEBNVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNVEBNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNSVEBNNNNSVEBNNNNNNNSVEBNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNVEBSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNSVEBNSVEBNVEBNNNNNVEBNNNNNVEBNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNNNNNVEBNVEBNVEBNVEBNNNNNVEBNNVEBNNVEBNVEBNNVEBNVEBNVEBNNNNNNNNNVEBNNNNNNNVEBNNNNNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNVEBNVEBNVEBNNNVEBNNVEBNNNNNVEBNNNNNNNNNNNNVEBNNVEBNNVEBNVEBNNVEBNNNNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNVEBNVEBNNNVEBNVEBNVEBNNNNNNNNNNNNVEBNNNVEBNVEBNNNVEBNVEBNNVEBNNVEBNNVEBNVEBNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNNNVEBNVEBNNNVEBNNNVEBNVEBNVEBNNVEBNNVEBNNVEBNVEBNVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNNNNNNNNVEBNVEBNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNVEBNVEBNNNNNNNNNNNNNNNVEBNVEBNNNVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNNNVEBNNNNNNNNVEBNVEBNNNVEBNVEBNVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNNVEBNNVEBNNVEBNVEBNNVEBNNVEBNNVEBNNNNNNNNVEBNNVEBNVEBNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNNNNVEBNNVEBNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNVEBNNVEBNNVEBNVEBNNNNNVEBNVEBNNNVEBNVEBNNNNNNVEBNNVEBNNVEBNNVEBNVEBNVEBNNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNVEBNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNVEBNNNVEBNVEBNNNVEBNNVEBNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNVEBNNNVEBNNNVEBNNNNVEBNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNVEBNNNNNVEBNNNNVEBNVEBNNNVEBNVEBNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNNNNNNNNNVEBNNVEBNVEBNVEBNNNVEBNNNNNNVEBNVEBNVEBNNNNNNNNVEBNVEBNVEBNNVEBNNNNVEBNVEBNVEBNNNVEBNNNNNVEBNNNNVEBNVEBNVEBNVEBNVEBNNNNNVEBNVEBNVEBNNNNVEBNVEBNVEBNVEBNVEBNNNNNVEBNNNNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNVEBNVEBNVEBNNNNVEBNVEBNNNNVEBNNNNVEBNVEBNNVEBNNNVEBNNNVEBNNVEBNVEBNNNVEBNNVEBNNVEBNNVEBNNNNNVEBNVEBNVEBNVEBNNNNNVEBNNVEBNVEBNNVEBNNNVEBNVEBNVEBNNNVEBNNNVEBNVEBNNVEBNVEBNNVEBNNVEBNNVEBNNVEBNVEBNVEBNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNVEBNVEBNNNNNVEBNNVEBNNNVEBNVEBNVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNNVEBNNVEBNVEBNNNNNNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNNNVEBNVEBNNVEBNNVEBNVEBNVEBNVEBNNVEBNNVEBNVEBNNVEBNNNVEBNVEBNNNVEBNVEBNNVEBNNNNVEBNNNNNVEBNVEBNNVEBNNNVEBNVEBNNVEBNVEBNNNVEBNVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNVEBNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNNVEBNNNVEBNVEBNVEBNNVEBNNNNNNVEBNNVEBNVEBNNNVEBNVEBNNNVEBNNNVEBNNNNVEBNNNVEBNNNNNNNNVEBNVEBNNNVEBNVEBNNNVEBNVEBNNNVEBNNNNVEBNVEBNNNVEBNNNNNVEBNVEBNNVEBNNVEBNNVEBNVEBNNVEBNVEBNNNNNNVEBNVEBNNNNVEBNVEBNNNNNVEBNNNNNNNNNNNNNNVEBNNVEBNNNNNNVEBNNNNNVEBNVEBNNVEBNNNNNVEBNNVEBNNNNNNNNNNNNVEBNVEBNNNNVEBNVEBNVEBNNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBVEBSVEBSVEBSVEBVEBSVEBSVEBSVEBSVEBSVEBSVEBFVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBFSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNFFVEBVEBVEBVEBVEBFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNNNVEBVEBVEBVEBVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNSVEBNSVEBNNNVEBNNSVEBNNNNNNSVEBNNNNNNNVEBNNNNNNSVEBNNVEBNNNNVEBSVEBSVEBNSVEBSVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNSVEBNNNNNNNNNNNSVEBNSVEBNNVEBSVEBNNNNNNNNNNNNVEBNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNSVEBNNVEBNNVEBNNNNVEBNNNNVEBNNNNVEBNNNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNVEBNSVEBNNNVEBNNVEBNNVEBNNVEBNNVEBNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNSVEBNNVEBNSVEBNNNVEBNNVEBNSVEBNNNVEBNSVEBNNNVEBNNNNNVEBNNSVEBNNNVEBNNVEBNNNSVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNSVEBNNVEBNNVEBNNVEBNNVEBNSVEBNNVEBNNVEBNNNSVEBNNVEBNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNVEBNNVEBNNVEBNSVEBSVEBNNVEBNNVEBNNVEBNNSVEBNNSVEBNSVEBNNNNNSVEBSVEBNNVEBNNNNNNNSVEBNSVEBNNNNNVEBNNNNNNNVEBSVEBSVEBNNVEBSVEBNNNVEBNNVEBSVEBSVEBNNVEBNSVEBNNVEBNNVEBNNVEBNNVEBSVEBSVEBNNNNVEBNSVEBSVEBNNVEBNNSVEBNNVEBNNVEBNNNSVEBNNVEBNNNVEBNSVEBSVEBNNNVEBSVEBSVEBNVEBNNVEBNSVEBNNVEBNNVEBSVEBNNNVEBSVEBNNNVEBNNVEBNNSVEBSVEBNNSVEBNNVEBNNNSVEBNNVEBNNNVEBNSVEBNNNVEBNNVEBNNNNVEBNSVEBNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBSVEBSVEBNNSVEBNNSVEBSVEBNNFNSVEBNSVEBNNSVEBNSVEBNNSVEBNSVEBNSVEBNNSVEBNSVEBNSVEBSVEBNSVEBNNSVEBNSVEBSVEBNSVEBNNSVEBNSVEBNSVEBNNSVEBNSVEBNNSVEBNSVEBNSVEBNNSVEBSVEBNSVEBSVEBNNNSVEBNNSVEBNNSVEBNNNVEBNNNSVEBNNSVEBSVEBNNNSVEBSVEBNSVEBSVEBNSVEBNNSVEBSVEBNSVEBSVEBNNSVEBNSVEBNFSVEBNNSVEBNNNSVEBNNSVEBSVEBSVEBNNNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNVEBVEBNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBVEBVEBNVEBNNNNNNNNNNVEBNNNNNNNNNNNVEBVEBNVEBNNNNNNVEBNVEBNNNNNNNNVEBNNNVEBVEBNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNVEBVEBVEBNVEBNSVEBNNNVEBVEBNSVEBNNNNNVEBNNNNNVEBVEBVEBNNNVEBVEBNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNVEBNNNNNVEBNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNVEBNVEBNNNVEBVEBNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBVEBNNNVEBNNNNVEBNNNNNNNNNVEBNVEBVEBVEBNNNNNNNNNNNVEBNVEBVEBNNVEBNNNNNNNVEBNVEBVEBNNNNNVEBNNNNVEBNNNNNNNNNVEBVEBVEBVEBNVEBVEBVEBVEBVEBVEBVEBVEBVEBNVEBNVEBNNVEBVEBNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNNNNNNNNNNNNVEBNNNNVEBNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNVEBVEBNNVEBNNNVEBNNNNNNNNNNNNNNNNVEBVEBNNVEBVEBNNNNNNNNNNNNNVEBNNNNVEBNNVEBNNNNVEBNNVEBNVEBNNNNNVEBNVEBNNNNNNNNNVEBNNNNVEBNNNVEBNNNNNNNNNVEBNVEBNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNVEBNNNNNNNNNVEBNNNVEBNNNVEBVEBVEBNNVEBNNNVEBNNVEBNNNNNNNNNNNVEBVEBNNNNNNNNVEBVEBNNNNNNVEBNNNNNNNNVEBNNNNNNNNVEBNNNNNNNVEBNNQNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNVEBNNNNNNVEBNNNNNNNNNNNVEBNNVEBNVEBNNNNNNVEBNVEBVEBNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNVEBNNNNVEBVEBNNNNNNNNNVEBVEBNVEBNNNNNNNNNVEBNNVEBVEBNVEBNNNNVEBNVEBNNNNNVEBNNNNNNVEBVEBVEBVEBNNNNNNNVEBNNNNNVEBNNNVEBNNNNNVEBVEBNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNVEBNNVEBVEBVEBNNNNNVEBNVEBNVEBVEBNNVEBNVEBNNNNNNNNNNNNNNNVEBVEBNNNNNNNNVEBNNNNNNNNNNNNNVEBVEBVEBVEBNVEBNNNNNNVEBVEBNNNNNNNVEBNNNVEBNNVEBNNNVEBVEBVEBVEBNNNVEBNNNNNVEBVEBNNVEBNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBVEBNNVEBVEBNNNNVEBNNNNNNNNNVEBNNNNNNNNNNVEBNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBVEBNNNNVEBNNNNNVEBNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNVEBNNNNNNVEBNNNNNNNNNVEBNVEBNNNVEBNNNNVEBNVEBNNNNNNNVEBNNNNVEBVEBNNNVEBNNNNNVEBNNNNNNNNNNNVEBNVEBNNVEBVEBNNVEBNNNVEBVEBVEBNNVEBNVEBNNNNNNVEBVEBNVEBNNNNNVEBNNNVEBNNNNNNNNNNNVEBVEBNNVEBVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBVEBNNNNNNVEBVEBVEBNNNNVEBNNNNNNNNNVEBNNNNNVEBNNNVEBNVEBNNNNNNNNVEBVEBVEBNVEBNVEBNVEBVEBVEBVEBNVEBNNNNNVEBVEBNNVEBNVEBNVEBNNNNVEBNNNNNNNNNNVEBNNNVEBNNNNNNNNNNVEBVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNVEBVEBVEBNNNNNNNNNNNNNNVEBVEBNNVEBVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNVEBNNNVEBVEBNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNVEBNNNNNVEBVEBNNNVEBNNNNNNNNNNNVEBVEBNNNNNVEBNNNVEBVEBNNNNNNNNNNNNNNNVEBNVEBVEBNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNQQQNNNNVEBNNNNVEBVEBVEBNNNVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNVEBNNVEBVEBNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBVEBNNVEBNVEBNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNVEBNNVEBNNNNNNNNVEBVEBNNNNNNNNNNNNVEBNNNVEBNNVEBVEBVEBVEBVEBVEBVEBNNNNNNNNNVEBNNNNNVEBVEBNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBVEBVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNVEBVEBNVEBNNNNNNNVEBNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBVEBVEBVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNVEBVEBNNNNNNVEBNFNNNNNVEBVEBNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNSVEBVEBVEBVEBVEBVEBVEBVEBVEBNNFVEBVEBVEBVEBVEBVEBVEBVEBVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNVEBNVEBVEBVEBNNNNNNNNNNNNNNNNNNFNNNNNFNNNNFNNNNNNNNNNNNNNNNNNNNNNFNNNNNNVEBNNNNNNNNNFNNNNNFNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBNVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBNSVEBNVEBVEBVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBVEBVEBNNVEBNNVEBVEBVEBNNNVEBNNNNNVEBNVEBNVEBNNVEBVEBNVEBVEBNNVEBNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNVEBNNNVEBVEBNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBNNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBFVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNNFNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNFNNNNNNVEBNNVEBNNFNNVEBNNVEBNNFNNNNNNVEBNNVEBNNFVEBNFVEBNNVEBNNFVEBNNVEBNNVEBNNVEBVEBNFVEBNFVEBNNVEBNNVEBNNVEBVEBNVEBVEBNFVEBNNNNNVEBVEBNVEBVEBNFVEBNNFNNNNNFVEBNFVEBNNVEBNNVEBNNFVEBNNNNNFVEBNVEBVEBNFVEBNNVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNNVEBNNVEBNNVEBNNVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNNVEBNNVEBNNVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNFVEBNFVEBNNFNNNVEBNNFVEBNNNNNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNNVEBNNVEBNFVEBNNVEBNNVEBNNNNNFVEBNFVEBNFVEBNNNNNVEBVEBNFVEBNNVEBNNFVEBNNNVEBNNNVEBNNNNNFVEBNNVEBNNNNNFVEBNVEBVEBNFVEBNNVEBNNVEBNFVEBNFVEBNNVEBNNNNNFVEBNFVEBNFVEBNNVEBNNFVEBNFVEBNNVEBNNFVEBNVEBVEBNVEBVEBNFVEBNNVEBNNVEBNNVEBNFVEBNFVEBNNVEBNNFVEBNFVEBNNVEBNNVEBVEBNVEBVEBNFVEBNNNNNVEBVEBNVEBVEBNFVEBNNVEBNNVEBNFVEBNFVEBNNVEBNNVEBNNVEBNNVEBNNFNNVEBNNNNFVEBNNVEBNNNNNFVEBNFVEBNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNVEBNNFVEBNNNNNNFNNNVEBNNNVEBNNFVEBNNNNNNVEBNNNVEBNNNVEBNNNFNNNNNNNNNNNFNNNVEBNNVEBNNVEBNNVEBNFVEBNVEBNNFVEBNNVEBNNFVEBNVEBNNFVEBNVEBNNNVEBNNFVEBNFVEBNFVEBNNFVEBNNVEBNNVEBVEBNFVEBNFVEBNNVEBNNVEBVEBNVEBNNFVEBNVEBVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNNNNNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNNFNNFVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFNNVEBVEBNVEBVEBNNNNNNNNNNNNNFVEBNFVEBNFVEBNNVEBNNFVEBNFVEBNNNNNFVEBNNVEBNFVEBNFVEBNFVEBNNVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNVEBVEBNVEBVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNFVEBNNVEBNNVEBNVEBVEBNFVEBNNNNNNNNNFVEBNFVEBNNNVEBNNFNNFVEBNNNVEBNNFVEBNVEBVEBNNVEBNNFVEBNFVEBNNVEBNNVEBNNFVEBNFVEBNFVEBNNVEBNNVEBNNVEBVEBNVEBVEBNVEBVEBNFVEBNFVEBVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBVEBNVEBNNFVEBNVEBVEBNVEBNNFVEBNNVEBNNFVEBNNNNNVEBVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBVEBNVEBVEBNVEBNNVEBNNVEBNNVEBNVEBVEBNVEBVEBNNFVEBNVEBVEBNVEBNNFNNVEBNVEBVEBNVEBVEBNFVEBNVEBVEBNVEBNNVEBNNVEBNNVEBNNVEBNNFVEBNNVEBNFVEBVEBNNNVEBVEBNNFVEBNVEBVEBNVEBNNFVEBNVEBVEBNVEBVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNFVEBVEBNNFVEBVEBNNFVEBNVEBVEBNFVEBNNFVEBNFVEBNVEBNNVEBVEBNNVEBNNVEBNSVEBVEBVEBNSVEBFVEBNVEBNNVEBNNVEBNNVEBVEBNNVEBNNVEBNNVEBNNVEBVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBVEBNVEBNNVEBNNVEBNFVEBVEBNNVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFFNFFNFNNNNNNNNFNNFNNNNNFNNNNNNNNNNNNNNFNNNNNFNNFNNFNNNNNNVEBNNVEBNNFNNNFNNVEBNNFNNFNNFNNNVEBNNFNNNNNNNFNNNNVEBNVEBNNFNNFNNVEBNNVEBNNVEBNNVEBNNVEBNNQNNFNNFVEBNNVEBVEBNVEBNNNQNNFNNVEBNNVEBNNFNNFNNVEBNNNNNVEBNNVEBNNFNNNNNNNNNNNNNNFNNFNNFNNNFNNNNNNVEBNNVEBVEBNNNNNVEBNVEBNFVEBNVEBNNVEBNNNNNVEBVEBNVEBNNNNNNFNNVEBNVEBNNFNNVEBNVEBNNFNNVEBNNVEBVEBNVEBNNVEBNNVEBNNVEBNVEBNNFNNNNNNNNNNNFNNNFNNFNNNVEBNNVEBNNVEBNVEBNNVEBNNFNNVEBNVEBNNVEBVEBNVEBNNVEBNNFNNVEBNNVEBNNVEBNNVEBNNFNNVEBNFVEBNNVEBNNVEBNNVEBVEBNVEBNNNVEBNNFNNNVEBNNFNNNVEBNNVEBNNFVEBNFNNVEBNNVEBNNFNNFVEBNVEBNNVEBNNVEBNNFNNVEBVEBNVEBNNFNNVEBNNVEBNNVEBNNVEBNNVEBVEBNFNNVEBNNFNNFNNNVEBNNVEBNFVEBNVEBNNNVEBNNVEBNFVEBNNVEBNNFNNVEBNNVEBNNVEBVEBNVEBNNNFNNFNNVEBNVEBNNFNNFNNVEBNNVEBNNFNNFNNFVEBNFVEBNNVEBNNVEBNNVEBNFVEBNFNNNVEBNFVEBNNVEBNNFVEBNNNNNNNNFNNNVEBNNFNNFVEBNNVEBNNFNNFVEBNVEBNNFNNVEBNNFNNVEBNNNVEBNNFNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBVEBNVEBNNVEBNNVEBNNVEBVEBNNNVEBVEBNNVEBNNVEBNVEBVEBNVEBNNVEBNNVEBNVEBVEBNVEBNFVEBNVEBNNVEBNNVEBNVEBNNVEBVEBNNVEBNNVEBVEBNNVEBNFVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNFNNFNNFNNVEBNFVEBNVEBNVEBVEBNVEBNFVEBNVEBNNVEBVEBNVEBNVEBVEBNNNFVEBVEBNNVEBNVEBNVEBVEBNVEBVEBNVEBNNVEBNNVEBVEBNNVEBNVEBNVEBVEBNVEBNVEBNNVEBNNVEBVEBNNVEBNVEBVEBNVEBNFVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBVEBNVEBNNVEBNNVEBNVEBVEBNVEBNVEBVEBNVEBNNFVEBNVEBVEBNVEBNVEBVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBNNVEBVEBNVEBNVEBNNVEBNNVEBVEBNVEBNFVEBVEBNNFVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNFVEBNVEBNFVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNSVEBNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNSVEBNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNVEBNNNNNNNNNNNNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNSVEBNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBVEBNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNVEBNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNVEBVEBVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNVEBNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNVEBVEBNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBFVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNSVEBSVEBSVEBNNSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBNNNSVEBNNNNNNNNSVEBSVEBSVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNSVEBSVEBNNNSVEBNNNNNNNSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNSVEBNNNNSVEBNNNSVEBSVEBSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNSVEBSVEBNNNSVEBSVEBNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNSVEBNNNSVEBSVEBNNNSVEBSVEBSVEBSVEBNNSVEBSVEBNNNSVEBSVEBNNNNNNNSVEBSVEBNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNSVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNVEBVEBNNNFNNNFNNNFNNNFNNNFNNNFNNNNNNNNNVEBNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNSVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNSVEBNNNNNNSVEBNNSVEBNNNNNNSVEBNNNNSVEBNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNSVEBNNNNNNNNNVEBNNNNNNNSVEBNNSVEBNNNSVEBNNFNVEBNVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBNSVEBSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNSVEBSVEBNNNNNVEBNVEBNFNFNFNFNVEBNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNNVEBNVEBNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNSVEBNVEBVEBNNNNNNNNNNNNNSVEBNVEBVEBNNSVEBSVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBVEBNVEBVEBVEBNVEBNVEBNVEBVEBNNNNVEBNNNNNNVEBNNNNVEBNNFNNNNVEBNNVEBNNVEBNSVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNFNVEBNVEBNVEBNSVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBVEBNVEBNVEBNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNVEBVEBNNNNSVEBNVEBVEBNNNNNNNNNNNNNNNNVEBNNNNFNSVEBNVEBVEBNNVEBNNVEBNNNNNNNVEBNNVEBNNVEBNVEBVEBNVEBVEBNNNNNNNNNNVEBNNVEBNNVEBNVEBVEBNVEBNVEBVEBVEBVEBVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNNNNNNNNNNSVEBNVEBVEBNNNSVEBNNNNNNNNSVEBNVEBVEBNVEBVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNSVEBNNNNNSVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNVEBVEBNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNSVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQNNNNQNNNNNNNNNNQNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNQNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNVEBNVEBNVEBVEBNVEBNVEBVEBNVEBNNNNNNNNNNNVEBNVEBVEBNVEBNNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNSVEBNNNNNNNVEBNVEBNVEBNVEBNVEBNNNVEBNVEBNVEBNVEBNVEBVEBNVEBNNNNNNNNNNSVEBNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNVEBNNNVEBNVEBNNNNNVEBNNNVEBNVEBNNNNNNNVEBVEBNNNNVEBNNNVEBNVEBNNNNNNNNNNNVEBNVEBNNNNNVEBNVEBNNNNNNNNNVEBNNNNNVEBNNNVEBNVEBNNNNNNNVEBNVEBNVEBNVEBNNNVEBNNNVEBNVEBNVEBNVEBNNNVEBNVEBNNNNNVEBNVEBNNNVEBNVEBNNNNNVEBNNNNNVEBNVEBNNNNNNNVEBNVEBNVEBNVEBNNNNNNNNNNNVEBNVEBNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNNNNNNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNSVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNSVEBVEBNVEBNNNNNNNNVEBNVEBNVEBNVEBNVEBNNNNNNVEBNVEBNVEBNVEBVEBNVEBNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNVEBNNVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNNNNNNSVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBVEBNVEBNNFNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNSVEBNVEBNVEBVEBVEBNVEBNVEBNNNNNNNNNVEBNVEBNVEBNVEBNNNVEBNVEBNVEBVEBNVEBNNNVEBNVEBNNNVEBNVEBNNNVEBVEBNNNVEBNVEBNNNVEBNNNVEBNNNVEBNVEBNNNVEBNVEBNNNVEBNVEBNNNVEBNVEBNNNVEBNVEBNNNNNNNNNVEBNVEBNNNNNNNNNNNNSVEBNVEBNVEBNVEBNNNVEBNVEBNVEBNNNVEBNVEBNNNSVEBNVEBNVEBNNNNNVEBNVEBNNNNNNNNNNNNNVEBNVEBNVEBNSVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNVEBNVEBNVEBNNNNNSVEBNVEBNVEBNVEBNVEBNVEBNNNVEBNVEBNVEBNVEBNNNVEBNVEBVEBNVEBNNNNNNNVEBNVEBNVEBNNNVEBNVEBNNNNNNNNNNNVEBNVEBNNNVEBVEBNNNNNNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNVEBNNNVEBNNNNNNNVEBNNNNNNNNNNNVEBNVEBNVEBNNNNNNNNVEBVEBVEBVEBNNNNVEBNVEBNNNNNNNNNVEBNVEBNVEBNVEBNVEBNSVEBNVEBNVEBNVEBNVEBNVEBNSVEBNVEBNVEBNVEBNVEBVEBNNNNNNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNNNNNNNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNNNNSVEBNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBFNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBVEBVEBVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNVEBVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNNNNNNNNVEBNVEBVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNNNNNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNSVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNSVEBNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNVEBNVEBNVEBVEBNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBVEBNNVEBNNNNNNNNNNNNNSVEBNVEBNVEBVEBVEBNVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNNNNSVEBNNNNNVEBNVEBNVEBNNNNNNSVEBSVEBNVEBVEBNVEBNNVEBNVEBNNVEBNVEBNVEBVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNNVEBNVEBNVEBNNNNNNNNNNNNSVEBNVEBNVEBNVEBNVEBVEBNVEBVEBNNNNNNNVEBNVEBNVEBNNNVEBNVEBNVEBNVEBNNNNNNNNNSVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNSVEBNVEBNVEBNNVEBNVEBNNNNVEBVEBNVEBNVEBNVEBNNNNNNNNSVEBNVEBNVEBNVEBNNNNNNNNNNNNNNSVEBNVEBNVEBNVEBNNNNVEBNVEBNVEBNVEBNNNSVEBNVEBNVEBNNVEBVEBNVEBNNNNNVEBNVEBNNNNNSVEBNVEBNVEBNNNNNNNNNNNNNNNVEBNVEBNNVEBNNVEBNVEBNNVEBVEBNVEBNNNNNNNNSVEBNNNNNNNVEBNVEBNNNNNVEBNVEBNVEBNNNSVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNSVEBNVEBNNNNNVEBNVEBNVEBNVEBNNNNNNNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNVEBNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBSVEBNNNNNNSVEBNNSVEBNNSVEBNNNVEBNNNNSVEBNNSVEBNNSVEBVEBNNNSVEBNNNSVEBNNNNNSVEBNNNSVEBNNSVEBNNNNNNNNNNNNNNSVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBSVEBNSVEBNSVEBNSVEBNSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBNSVEBNSVEBSVEBNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBFSVEBSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNFNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNVEBNNVEBNVEBNNVEBNNVEBVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBVEBVEBVEBVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNFNNNNNNNNNNNNFNNVEBNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBVEBNNNNVEBNNNNNNNNNNNNNSVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNVEBSVEBNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBVEBNNNNVEBVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNVEBNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNSVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNVEBNNNNNNFNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBFNNVEBNVEBVEBVEBVEBVEBVEBNVEBNVEBNNNVEBNVEBNVEBNFNNNVEBNNNFNNVEBNVEBNVEBNVEBVEBNVEBVEBNVEBNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBVEBNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNSVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNSVEBVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNSVEBNNNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNSVEBNVEBNNNSVEBSVEBNNNNNNNNNSVEBNNNNNNNNNNNNNNNNVEBNVEBNVEBNNNVEBNVEBNNVEBNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNVEBNVEBNSVEBVEBVEBVEBFNNNVEBNNNNNVEBNVEBNNNNNVEBNNNNNNNNNNNVEBNNNVEBNVEBNNNSVEBVEBNVEBNNNNNNNNNNVEBNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNFNFNFNVEBNFNFNFNNNFNFNFNFNFNFNFNFNFNFNFNVEBNFNFNFNNNNNNNNNFNFNVEBNVEBNVEBNFNNNFNFNFNFNVEBNFNFNFNFNFNFNVEBNVEBNFNFNNNNNNNFNVEBNNNFNFNFNFNFNFNNNNNFNVEBNVEBNFNFNFNFNNNNNFNVEBNVEBNFNFNFNFNFNFNFNFNFNFNVEBNFNNNNNFNVEBNFNFNFNFNFNFNFNFFNNNNFNFNFNFNFNFNFNFNFNNNNNNNFNVEBNFNNNNNNNFNFNVEBNNNNNNNNNFNFNFNVEBNNNNNNNNNNNNNVEBNVEBNVEBNFNNNFNNNNNNNFNVEBNNNNNNNNNFNVEBNNNNNNNNNNNNNNNNNFNVEBNVEBNFNNNNNFNVEBNVEBNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNVEBNVEBNVEBNNNNNNNFNVEBNVEBNNNNNNNNNNNFNVEBNNNNNNNNNNNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNSVEBNNNNNNVEBNNNNNNNNNNNFNVEBNVEBNFNFNFNFNFNVEBNVEBNFNFNFNVEBNVEBNVEBNFNFNVEBNNNVEBNFNVEBNVEBNVEBNFNFNFNFNVEBNVEBNVEBNNNNNFNFNFNVEBNVEBNVEBNFNFNFNFNFNVEBNVEBNFNNNNNNNVEBNVEBNNNNNNNNNSVEBNVEBNNNFNFNVEBNFNFNFNVEBNVEBNFNFNFNFNFNFNFNFNVEBNFNVEBNFNFNFNFNVEBNFNFNNNNNNNFNFNVEBNFNNNNSVEBNNNNFNVEBNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNVEBNNNVEBNFNFNFNFNFNFNFNFNFNNNFNFNFNFNFNNNFNFNFNFNFNFNFNFNFNFNNNNNNNNFNNVEBNVEBNVEBNFNNNNNNNNNVEBNNNNNNNNNFNVEBNVEBNVEBNNNNNNNNNFNVEBNVEBNFSVEBNNNNNNNNVEBNFNNSVEBNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNFNVEBNVEBNFNFNFNFNVEBNVEBNVEBNVEBNFNFNFNFNFNFNFNVEBNVEBNVEBNFNNNNNNNFNVEBNVEBNVEBNVEBNVEBNNNNNNNNNFNVEBNNNNNNNFNVEBNNNVEBNVEBNFNFNFNFNFNVEBNVEBNFNFNNNNNFNVEBNVEBNFNFNFNFNFNVEBNFNFNNNNNNNNNFNNNFNNNNNSVEBNVEBNNNNNNNNNFNVEBNVEBNVEBNNNNNNNNNFNVEBNVEBNNNNNNNNNNNFNNNVEBNNNNNVEBNNNNNNNNNSVEBVEBNNNNFNFNNNNNNNNNFNVEBVEBFNNNNNNNFNVEBNNNNNNNNNNFVEBNFNNNNNNNNNVEBNFNFNNNNNNNSVEBNVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNFNFNVEBNVEBNVEBNVEBNFNFNFNFVEBVEBVEBVEBNFNNNFNVEBNVEBNVEBNFNFNFNVEBNFNVEBNFNFNVEBNVEBNVEBNVEBNVEBNVEBNFNVEBSVEBVEBNNFNVEBNNNNNNNNNNNFNVEBNNNNNNNNNNNFNNNVEBNVEBNFNFNFNNNNNNNFNFNNNNNNNNNNNFNVEBNVEBNFNNNNNNNNNVEBNNNVEBNFNFNFNFNFNFNVEBNFNNNNNNNNNNNFNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNFNVEBNFNFNFNFNNNNNFNFNFNNNNNNNFNVEBNFNFNFNFNVEBNNNNNNNNNFNVEBNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNFNFNFNFNFNFNFNVEBNNNFNFNVEBNFNVEBNFNVEBNFNFNFNFNFNVEBNFNVEBNFNFNFNFNFNVEBNFNNNNNNNFNVEBNNNNNFNNNNNNNNNFNVEBNNNVEBNVEBNVEBNFNNNNNNNNNVEBNVEBNVEBNFNNNNNNNNNNNFNVEBFVEBNNFFNFNFNFNVEBNFNNNNNNNFNVEBNNNNNNNFNFNVEBNFNNNFNNNFFVEBNFNFNNNNNNNFNNNFNFNVEBSVEBNNNNNNNNFNVEBNNNNNNNNNNNNNVEBNNNFNFNSVEBNVEBNFNFNNNNNNNNNNNNNFNNNNNNNNNNNNNFNNNFNNNNNNNNNNNFNVEBNSVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNFNVEBNVEBNVEBNNNFNFNFNFNVEBNFNFNFNVEBNVEBNFNVEBNVEBNVEBVEBNNNNNNVEBNNNVEBNNNNNNNNVEBNNNVEBNNNNNNVEBNNNNNNVEBNNNNNNNNFNNNNNVEBNNNVEBNFNFNFNFNNNSVEBNFNNNNNNNNNNNNNNNVEBNNNVEBNFNNNNNNNNNNNVEBNVEBNNNNNNNNNFNVEBNNNVEBNNNNNNNNNNNFNVEBNNNVEBNNNNNNNNNFNFNVEBNVEBNFNNNNNNNNNFNFNVEBNNNNNNNNNNNFNVEBNFNNNNNNNNNNNNNNNFNFNVEBNNNNNNNNNNNNNSVEBNNNNNNNNNNNVEBNVEBNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNVEBNFNFNNNNNNNNNNNNNFNVEBNFNNNNNNNNNNNNNNNNNFNNNNSVEBNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNNVEBNNNVEBVEBNNNNNNNNVEBNNNVEBNNVEBNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNVEBNNNNNNVEBNNNVEBNNNNVEBNNNNNVEBNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNNNNNNNNVEBNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBVEBNNVEBNNNNNNNNNNNNNNNNVEBQQNNNNNVEBNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNVEBVEBVEBNNNNNVEBNNVEBNNVEBNNNNNNVEBNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNNNVEBNNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNVEBNNNNNNVEBNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNVEBNNVEBNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNVEBNNNNNNNNNNNNNNNVEBNNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNVEBNNNVEBNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNVEBNNVEBNNNNNNVEBNNNNNVEBNNNNNNNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNVEBNNNNNVEBNNNNVEBNNNNNNNVEBVEBVEBNNNNNVEBNNNNNNNNNNVEBVEBNNNNNNVEBNNNNVEBNNNNNNNNNNVEBNNNNNNNVEBNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNVEBNNNNNNNVEBNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNVEBNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNVEBNNNNNVEBNNVEBNNVEBNNNNNVEBNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNVEBNNNNNNVEBNNNVEBNNNNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNVEBNVEBNNNNNVEBNNNNNNNNNNNNVEBNNNNVEBNNVEBNNVEBNNNNNVEBNNNNNVEBVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNVEBNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNVEBNNNVEBNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNVEBNNVEBNNNNNNNNVEBNNVEBNNNNNVEBNNNNNNNNNNNNNNVEBNNVEBNNNNNNNVEBNNNVEBNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBFNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNVEBNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNVEBNNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNSVEBNNNNNNNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNVEBNVEBNVEBNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNVEBNNVEBNNNVEBNNNNNNNNNVEBNNNVEBNNNVEBNNNNNNNNNNVEBNNNVEBNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNVEBNNNVEBNNNNNNNVEBNNNNNNNNNVEBNNNVEBNNNVEBNNNNVEBNNNNVEBNNNNNNNNVEBNNVEBNNNNVEBNNNNNVEBNNNVEBNNNNNNNVEBNNNVEBNNNNVEBNNVEBNNNNNNVEBNNVEBNNNVEBNNNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNNNNNNVEBNNNNNNNNNVEBNNNVEBNNNNNNNVEBVEBNVEBNNVEBNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNVEBNNNNVEBNNNVEBNNNVEBNNNNNNVEBNNNVEBNNNVEBNNNNVEBNNNNVEBNNVEBNNNNVEBNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNVEBNNNNNNNNNNNNVEBNNNVEBNNNVEBNNNNNNVEBNNNNVEBNNNNVEBNNNNNVEBNNVEBNNNNVEBNNVEBNNNVEBNNVEBNNVEBNNNNVEBNNNVEBNNVEBNNNNVEBNNNNNVEBNNVEBNNNVEBNNNNNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNVEBNNNNVEBNNNVEBNNNNNNNNVEBNNVEBNNNNNVEBNNNNVEBNNNNVEBNNNVEBNNNVEBNNVEBNNNNNNNNNVEBNNNVEBNNNNVEBNNNNVEBNNVEBNNVEBNNNNNNVEBNNNNNNVEBNNVEBNNNVEBNNNVEBNNVEBNNNNVEBNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNVEBNNNVEBNNNVEBNNNNVEBNNVEBNNNNVEBNNNVEBNNNNNNVEBNNNVEBNNNNNNNVEBNNNNNNVEBNNVEBNNNNNNNNNNNVEBNNNNNNVEBNNNVEBNNNNVEBNNVEBNNNNNNNNVEBNNNVEBNNVEBNNNNVEBNNNVEBNNNVEBNNVEBNNNVEBNNNNNVEBNNNNNNVEBNNNVEBNNVEBNNVEBNNNNNNNVEBNNNVEBNNVEBNNNNVEBNNNVEBNNNNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNNVEBNNNVEBNNNVEBNNVEBNNNNNNVEBNNNVEBNNNVEBNNNNNNVEBNNNNVEBNNNNVEBNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNVEBNNNVEBNNNNNNVEBNNVEBNNNNVEBNNNVEBNNNNNNVEBNNVEBNNNNVEBNNVEBNNNNNNVEBNNNVEBNNNNNVEBNNVEBNNVEBNNNNVEBNNNNVEBNNNNNNVEBNNVEBNNVEBNNNNVEBNNVEBNNNNNNNVEBNNNNNVEBNNNVEBNNVEBNNVEBNNNVEBNNNVEBNNNNVEBNNNNNNNNNNNNNVEBNNNVEBNNNVEBNNNNNVEBNVEBNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNNNNNVEBVEBVEBNNNNVEBNNNNNNNNNVEBNNNNNVEBNNVEBNNNNNNVEBNVEBNNNNNVEBNNNNVEBNNNNNVEBNNNNNNNNVEBNNNVEBNNVEBNNNVEBNNNVEBVEBVEBNNNNNNNVEBNNNNNVEBNNNNNVEBNNNNNNNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNVEBNNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNNNVEBNNVEBNNNNNNVEBNNVEBNNNNVEBNNNNNNNNVEBNNVEBNNNVEBNNNNNNVEBNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNVEBNNNNNVEBNNNNVEBNNNVEBNNNNNNNNNNNVEBNNVEBNNVEBNNVEBNNNNNNNNNNNNNVEBNNNVEBNNNNNVEBNNNVEBNNNNNNVEBNNVEBNNNVEBNNNNVEBNNNNVEBNNNNVEBNNVEBNNVEBNNNVEBNNVEBNVEBNNNVEBNNNVEBNNVEBNNNNVEBNNVEBNNNNNVEBNNNNVEBNNNNVEBNNNNVEBNNNVEBNNNVEBNNNVEBNNNNNVEBNNNNNNVEBNNNVEBVEBNVEBNNNNNNVEBNNNVEBNNNVEBNNNVEBNNNNNVEBNNNVEBNNNNNNNNVEBNNNNVEBNNNVEBNNNNNNNVEBNNNNVEBNNVEBNNNVEBNNNVEBNNNNNVEBNNNVEBNNVEBNNNVEBNNNVEBNNVEBNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNVEBNNNNVEBNNNVEBNNNNVEBNNVEBNNNVEBNNNNNVEBNNNNNNNNNNVEBNNNVEBNNNNNVEBNNNNNNNNNNVEBNVEBNNNVEBNNNNNVEBNNNNVEBNNVEBNNNVEBNNNNNNVEBNNVEBNNNNNNNVEBNNNVEBNNVEBVEBNNNVEBNNVEBNNNNNNNNNVEBNNNVEBNNNNVEBNNNNNNVEBNNVEBNNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNNNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNVEBNNNVEBNVEBNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNVEBNNNNVEBNNNNNVEBNNNNNNNNNVEBNNVEBNNNVEBNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNVEBNNNVEBNNNNNNNVEBNNNNNNNNNNNNNVEBNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNVEBNNNNNVEBNNNNNNNNVEBNNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNNNSVEBNNSVEBNSVEBNSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNNSVEBNNSVEBNNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNSVEBSVEBSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNSVEBNNNSVEBNSVEBSVEBNSVEBNNNNNNNNNNNNNNNNNNSVEBNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNNSVEBNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNSVEBNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBNNNNNNNNNNSVEBNSVEBSVEBNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNSVEBNNSVEBNNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNSVEBNSVEBNSVEBNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNSVEBNNNNSVEBNNNNNSVEBNSVEBNNNNNNNNNNNNNNNSVEBNNNSVEBNNNNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNNNSVEBSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNNNNSVEBNSVEBSVEBNSVEBSVEBNSVEBNNNNNNNNNNNNNSVEBSVEBNSVEBNNSVEBSVEBNSVEBNNNNNNNNNNNNNNNNNNNNSVEBNSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNSVEBSVEBNNSVEBNNNNNNNNSVEBSVEBSVEBSVEBNNNNNSVEBSVEBNNSVEBSVEBSVEBNNNNNNNNSVEBNSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNSVEBNSVEBNSVEBNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNSVEBNNSVEBNNNNNNNNNNNNNNNNNNNSVEBSVEBNSVEBNSVEBNNNSVEBNNNNNNNSVEBNNNNNNNNSVEBSVEBNSVEBNNNNNNNNNNNSVEBSVEBNSVEBNNNNNNNNNNNNSVEBNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNSVEBNNNNNNNNNNNSVEBSVEBNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNVEBVEBNNNNNNNVEBNNNVEBNVEBNNNNNNNNNNNNNNNNVEBNNNNNNVEBNVEBNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNNNVEBNVEBNVEBNNNNNNNNNNNNNVEBNVEBNVEBNNNVEBNNNNNVEBNNNNVEBNNNVEBNNNNNVEBNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNVEBNNNNNNNNNVEBNVEBNNNVEBNNNNNNNNVEBNVEBNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNVEBNNNNNVEBNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNVEBNNNNNVEBNVEBNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNVEBNVEBNNNNNNVEBNNNVEBNVEBNNNNNNNNVEBNNNNVEBNNNNVEBNNNNNNNNVEBNVEBNNNNVEBNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNVEBNVEBNVEBNNNNNNVEBNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNNVEBNVEBNVEBNVEBNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNNNNNNNNNNNVEBNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNVEBNVEBNVEBNNNNNNNNVEBNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNVEBNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNVEBNVEBNNNNNNNVEBNNNNNNNNVEBNNNSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNVEBNNNNNNVEBNNNVEBNNNNNNNVEBNNNNNNNVEBNNNNNVEBNNNNNNNNNNNVEBNNNNNVEBNVEBNNNNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNVEBNVEBNVEBNNNNNVEBNNNNNNVEBNVEBNVEBNNNNNNVEBNNNVEBNNNNNNVEBNVEBNVEBNNNNNNNNNVEBNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNNVEBNNNNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNVEBNNNNNVEBNNNNNNNVEBNNNNNVEBNNNVEBNVEBNNVEBNNSVEBNNNNNNVEBNNNNNNNNNNVEBNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNNVEBNVEBNNNNNNNNNNNNVEBNNNNVEBNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNVEBNVEBNVEBNNNNNVEBNVEBNVEBNVEBNVEBNVEBNNNNNVEBNVEBNNNNVEBNNNNNNNNNNNVEBNVEBNNNNNNVEBNNNNNNNNVEBNVEBNNNNVEBNVEBNNNNSVEBNVEBNNNNVEBNVEBNVEBNNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNVEBNVEBNNNNNNVEBNNNNNNVEBNNNNNNNNNVEBNNNNNVEBNNNNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNVEBNNNNVEBNNNNNNNNNNNNVEBNNNNVEBNVEBNNNNNVEBNVEBNVEBNNNNNNVEBNNNNNNVEBNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBNVEBVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBNSVEBSVEBNSVEBNSVEBNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBNSVEBNSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBNSVEBSVEBNSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNSVEBSVEBSVEBSVEBNSVEBVEBNVEBNNVEBNVEBNNVEBNNNVEBNNNNNNVEBNVEBNNSVEBVEBNNNNNNNSVEBNNVEBNNNVEBNNNNVEBVEBVEBNVEBNNVEBNVEBNNVEBNVEBNNNVEBNNVEBNVEBNNNVEBVEBNVEBNNNNNVEBNNNVEBNNNNNVEBNNNVEBNNVEBNNNNNNVEBNVEBNNVEBNVEBNNNNNVEBNNVEBNVEBNNVEBNNNVEBNNNVEBNNVEBNNVEBNNNNNNNNNNNVEBNNNNNVEBNNNVEBNNNNNVEBNNNNNNNVEBNNNNNNNNNNNNNNNVEBNNNNNNNVEBNNNNVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNVEBNNVEBNSVEBNNVEBNVEBNVEBNVEBNNNVEBNNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNVEBNNVEBNFVEBNNNVEBNNVEBNNVEBNVEBNNNNNNVEBNVEBNNNVEBNNNVEBNNNNNNVEBNVEBNNVEBNVEBNNVEBNVEBNNNVEBNNNVEBNNVEBNVEBNNNNNNNNNNVEBNVEBNNVEBNVEBNVEBNNNNNNNNVEBVEBNNVEBFNVEBFNNNVEBVEBNNNNNNNNVEBVEBNNNNVEBNNNNNNNVEBNVEBNNVEBNVEBNNNNNNNNNNNNNNNVEBNFNNNVEBVEBNVEBNNNNNVEBNNVEBNNNNNVEBNNNNNVEBNNNNNNVEBNNNVEBNVEBNNNFNNNNVEBNNNVEBNVEBNNNNNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNVEBNVEBNVEBNNNNNVEBNNNVEBNVEBNVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNVEBVEBNNNNNVEBNNNVEBNNNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNVEBNNNNVEBNVEBVEBNVEBNVEBNNVEBNVEBNNNVEBNNVEBVEBNVEBNNNVEBNNNNVEBNNNVEBVEBNVEBNNNNNNNNNNNNNNNNNVEBNNVEBNNNNNVEBNNNNNVEBNFNNNVEBFNNNNNVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNVEBNNNVEBNNNVEBNNNVEBNVEBNNNVEBNNNVEBVEBNNNNNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNNNNNVEBNVEBVEBNNNVEBNNNVEBNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBVEBNVEBNNNNNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNVEBNNNNNNVEBVEBNVEBNNNVEBVEBNNNNNVEBNVEBVEBNVEBNVEBNVEBNVEBNNNVEBNFNNNNNNNVEBVEBNVEBNVEBNNVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNNNNNNNVEBNNVEBNVEBNNVEBNNNNNNNVEBNNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNVEBNNVEBNVEBNNNVEBNNNNNNVEBNVEBNNNVEBVEBNVEBNNVEBNNNNNVEBNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNNVEBNVEBNNVEBNNNVEBNNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNNNVEBNNNVEBNNVEBNNNNNNNVEBNNVEBNVEBNNVEBNNNNNNNNNNNNNNNNNNNNVEBVEBNVEBNNNVEBVEBNNNNNVEBNNNVEBNNNNNVEBNNNNNNNNNNVEBNNNNNNNVEBNVEBNVEBNNNVEBNNVEBNNNNNNNVEBNNVEBNNNNNVEBNNNVEBNNNVEBNVEBNVEBNNVEBVEBNNNVEBNNNNNVEBNNNNNNVEBNVEBNVEBNVEBNVEBNNVEBNVEBNVEBNNNVEBNFVEBNVEBNVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNNVEBNVEBNNVEBNVEBNVEBNVEBNNNVEBNNNVEBNNVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNNNVEBNNVEBNVEBNNVEBNVEBNNNNNNNNNNNNNNNNVEBNNNVEBNVEBNNNVEBNVEBNNNNNVEBNVEBNNNNNNNNNNNNVEBNNNVEBNNNVEBNNNNNNNFNNVEBNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNVEBNVEBNVEBVEBNNNNNNNNNNNNNNNVEBNVEBNNNNVEBNVEBNNVEBNVEBVEBNNNVEBNVEBNNVEBNVEBNNVEBNVEBNNNNNVEBNVEBNVEBNNNVEBNNNVEBNNVEBNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNVEBNNNNNVEBNVEBNNNNNVEBNNNSVEBNNVEBNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNNNVEBNVEBNNVEBNVEBNNVEBNVEBNNVEBNVEBNNNNNVEBNNNVEBNNNNNVEBNNNNNVEBNVEBNNNNNNNNVEBNVEBNNNVEBVEBNVEBNNNNNVEBNNNSVEBNNNVEBNNNVEBNNNVEBNNSVEBNNNNNNVEBNNNVEBNNVEBNNNVEBNVEBNVEBNNNNNVEBNNNNNNNNNVEBNNNNNVEBNNNNNNNNNVEBNVEBNNNNVEBVEBNVEBNVEBNNVEBNVEBNNNNNNVEBNVEBNNNNNVEBNNNNNVEBVEBNVEBNNNNNNVEBNVEBNNNVEBVEBNVEBNNVEBNVEBNNVEBNVEBVEBNNNVEBNNVEBNVEBNNVEBNVEBNVEBNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNVEBNNNVEBNVEBNNNNVEBNNNVEBNNNNNVEBNNNVEBNNNVEBNVEBNNNNVEBNNNVEBNNNVEBNVEBNNNVEBVEBNVEBVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNVEBNNNVEBNNNVEBNNNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNNNVEBVEBNVEBNNNNNVEBNNNVEBVEBNVEBNVEBNNNVEBNNNVEBVEBNNNNVEBVEBNNVEBNNVEBVEBVEBNVEBVEBNVEBVEBVEBNVEBNNNNVEBNVEBVEBNNNVEBNNVEBNNNVEBNNNVEBVEBVEBNNNVEBNVEBNNNNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNVEBNVEBNVEBNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNVEBNNNNNNNNNVEBNNNVEBNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNVEBNVEBVEBNNNVEBNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBVEBNNVEBNVEBNNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNVEBNVEBNNNNNNNNVEBNVEBVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNVEBNNNFNNNVEBNVEBVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNVEBNVEBNVEBNVEBNNNNNVEBVEBNNNVEBNVEBNNNVEBNNVEBNNVEBNVEBNNVEBNNNVEBNNNVEBNSVEBNNNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNNNVEBVEBNVEBNNNVEBNVEBNVEBNNNVEBVEBVEBNVEBNNNNNVEBNVEBNNNVEBNNNVEBNNNVEBVEBNVEBNVEBNNVEBNVEBNNVEBNVEBNNNNVEBNNNNNNNVEBNNNVEBVEBNVEBNNVEBNVEBNVEBNVEBNVEBNNNNNVEBNNNVEBNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBSVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNVEBNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN'] to numeric"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense\n",
    "\n",
    "# Load your dataset (replace 'path/to/MITBIH_dataset.csv' with the actual path)\n",
    "dataset_path = \"MITBIH.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Impute missing values with mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Check if there are enough samples for splitting\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"Not enough samples after imputing missing values.\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for RNN + LSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Build the RNN + LSTM model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92df948e-2a53-42de-8ece-66d4100615c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\yarra\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yarra\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19bc36a3-a56a-4023-a77e-4231cd9648d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8723 - loss: 7.6750 - val_accuracy: 0.9256 - val_loss: 0.3546\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.2707 - val_accuracy: 0.9513 - val_loss: 0.1972\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.2397 - val_accuracy: 0.9455 - val_loss: 0.2529\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.2076 - val_accuracy: 0.9457 - val_loss: 0.2375\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9492 - loss: 0.1988 - val_accuracy: 0.9586 - val_loss: 0.1523\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1863 - val_accuracy: 0.9515 - val_loss: 0.1671\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.1632 - val_accuracy: 0.9564 - val_loss: 0.1963\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.1708 - val_accuracy: 0.9684 - val_loss: 0.1185\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.1551 - val_accuracy: 0.9612 - val_loss: 0.1280\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.1397 - val_accuracy: 0.9601 - val_loss: 0.1347\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.6538 - val_accuracy: 0.9479 - val_loss: 0.2222\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.1913 - val_accuracy: 0.9486 - val_loss: 0.1814\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9521 - loss: 0.1550 - val_accuracy: 0.9555 - val_loss: 0.1304\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9577 - loss: 0.1353 - val_accuracy: 0.9626 - val_loss: 0.1180\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.1190 - val_accuracy: 0.9712 - val_loss: 0.1002\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9707 - loss: 0.0990 - val_accuracy: 0.9739 - val_loss: 0.0899\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.0876 - val_accuracy: 0.9695 - val_loss: 0.0958\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9761 - loss: 0.0832 - val_accuracy: 0.9723 - val_loss: 0.0950\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0767 - val_accuracy: 0.9764 - val_loss: 0.0844\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.0726 - val_accuracy: 0.9749 - val_loss: 0.0799\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13ms/step - accuracy: 0.9062 - loss: 0.3526 - val_accuracy: 0.9421 - val_loss: 0.1634\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9494 - loss: 0.1528 - val_accuracy: 0.9605 - val_loss: 0.1207\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.9564 - loss: 0.1383 - val_accuracy: 0.9669 - val_loss: 0.1047\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 14ms/step - accuracy: 0.9664 - loss: 0.1115 - val_accuracy: 0.9712 - val_loss: 0.0978\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 14ms/step - accuracy: 0.9693 - loss: 0.1031 - val_accuracy: 0.9752 - val_loss: 0.0855\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9726 - loss: 0.0903 - val_accuracy: 0.9760 - val_loss: 0.0792\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0819 - val_accuracy: 0.9770 - val_loss: 0.0739\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9770 - loss: 0.0754 - val_accuracy: 0.9758 - val_loss: 0.0826\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.9769 - loss: 0.0796 - val_accuracy: 0.9794 - val_loss: 0.0713\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 14ms/step - accuracy: 0.9797 - loss: 0.0713 - val_accuracy: 0.9148 - val_loss: 0.2907\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "HardC Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Print classification reports\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHardC Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true_original, y_pred_hardc))\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCNN Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true_original, y_pred_cnn))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2313\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2310\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2313\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n\u001b[0;32m   2314\u001b[0m     labels_given \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:117\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(label, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ys_labels)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMix of label input types (string and number)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28msorted\u001b[39m(ys_labels))\n",
      "\u001b[1;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, LSTM, Bidirectional, SimpleRNN\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MIT-BIH Arrhythmia dataset\n",
    "# Assuming 'mitbih.csv' is your dataset file\n",
    "dataset_path = 'MITBIH.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN and LSTM\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the HardC model\n",
    "hardc_model = Sequential()\n",
    "hardc_model.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "hardc_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "hardc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the HardC model\n",
    "hardc_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the CNN model\n",
    "cnn_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Build the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "lstm_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the LSTM model\n",
    "lstm_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions using each model\n",
    "y_pred_hardc_prob = hardc_model.predict(X_test)\n",
    "y_pred_hardc = y_pred_hardc_prob.argmax(axis=1)\n",
    "\n",
    "y_pred_cnn_prob = cnn_model.predict(X_test_reshaped)\n",
    "y_pred_cnn = y_pred_cnn_prob.argmax(axis=1)\n",
    "\n",
    "y_pred_lstm_prob = lstm_model.predict(X_test_reshaped)\n",
    "y_pred_lstm = y_pred_lstm_prob.argmax(axis=1)\n",
    "\n",
    "# Convert true labels back to original labels\n",
    "y_true_original = label_encoder.inverse_transform(y_test.argmax(axis=1))\n",
    "\n",
    "# Print classification reports\n",
    "print(\"HardC Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_hardc))\n",
    "\n",
    "print(\"\\nCNN Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_cnn))\n",
    "\n",
    "print(\"\\nLSTM Classification Report:\")\n",
    "print(classification_report(y_true_original, y_pred_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdf7a2e-9aea-4a02-b36b-ce214b91a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 1.0164 - val_accuracy: 0.9407 - val_loss: 0.3542\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.2420 - val_accuracy: 0.9450 - val_loss: 0.1979\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.2188 - val_accuracy: 0.9482 - val_loss: 0.1816\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.2092 - val_accuracy: 0.9534 - val_loss: 0.1743\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.2080 - val_accuracy: 0.9493 - val_loss: 0.2001\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9521 - loss: 0.1722 - val_accuracy: 0.9499 - val_loss: 0.2412\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1701 - val_accuracy: 0.9569 - val_loss: 0.1508\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 0.1618 - val_accuracy: 0.9541 - val_loss: 0.1425\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.1511 - val_accuracy: 0.9564 - val_loss: 0.1390\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1349 - val_accuracy: 0.9552 - val_loss: 0.1445\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 1.3620 - val_accuracy: 0.9497 - val_loss: 0.1621\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9464 - loss: 0.1894 - val_accuracy: 0.9557 - val_loss: 0.1467\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1493 - val_accuracy: 0.9571 - val_loss: 0.1283\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9584 - loss: 0.1344 - val_accuracy: 0.9656 - val_loss: 0.1166\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9650 - loss: 0.1147 - val_accuracy: 0.9707 - val_loss: 0.1073\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.1023 - val_accuracy: 0.9724 - val_loss: 0.0933\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.0927 - val_accuracy: 0.9731 - val_loss: 0.0967\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.0847 - val_accuracy: 0.9734 - val_loss: 0.0875\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9768 - loss: 0.0790 - val_accuracy: 0.9746 - val_loss: 0.0856\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9763 - loss: 0.0792 - val_accuracy: 0.9799 - val_loss: 0.0771\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13ms/step - accuracy: 0.9187 - loss: 0.3590 - val_accuracy: 0.9582 - val_loss: 0.1450\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9433 - loss: 0.1956 - val_accuracy: 0.9456 - val_loss: 0.1625\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9551 - loss: 0.1466 - val_accuracy: 0.9618 - val_loss: 0.1224\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9592 - loss: 0.1339 - val_accuracy: 0.9683 - val_loss: 0.1077\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - accuracy: 0.9661 - loss: 0.1112 - val_accuracy: 0.9722 - val_loss: 0.0917\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 14ms/step - accuracy: 0.9694 - loss: 0.1007 - val_accuracy: 0.9633 - val_loss: 0.1220\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - accuracy: 0.9717 - loss: 0.0922 - val_accuracy: 0.9746 - val_loss: 0.0850\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9733 - loss: 0.0876 - val_accuracy: 0.9746 - val_loss: 0.0808\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 14ms/step - accuracy: 0.9760 - loss: 0.0802 - val_accuracy: 0.9719 - val_loss: 0.0919\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.9755 - loss: 0.0815 - val_accuracy: 0.9801 - val_loss: 0.0630\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:224\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:158\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m y_pred_lstm \u001b[38;5;241m=\u001b[39m y_pred_lstm_prob\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Convert true labels back to numerical labels\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m y_true_numerical \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mtransform(y_test\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Print classification reports\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHardC Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:139\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _encode(y, uniques\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:226\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MIT-BIH Arrhythmia dataset\n",
    "# Assuming 'MITBIH.csv' is your dataset file\n",
    "dataset_path = 'MITBIH.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN and LSTM\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the HardC model\n",
    "hardc_model = Sequential()\n",
    "hardc_model.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "hardc_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "hardc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the HardC model\n",
    "hardc_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the CNN model\n",
    "cnn_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Build the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "lstm_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the LSTM model\n",
    "lstm_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Make predictions using each model\n",
    "y_pred_hardc_prob = hardc_model.predict(X_test)\n",
    "y_pred_hardc = y_pred_hardc_prob.argmax(axis=1)\n",
    "\n",
    "y_pred_cnn_prob = cnn_model.predict(X_test_reshaped)\n",
    "y_pred_cnn = y_pred_cnn_prob.argmax(axis=1)\n",
    "\n",
    "y_pred_lstm_prob = lstm_model.predict(X_test_reshaped)\n",
    "y_pred_lstm = y_pred_lstm_prob.argmax(axis=1)\n",
    "\n",
    "# Convert true labels back to numerical labels\n",
    "y_true_numerical = label_encoder.transform(y_test.argmax(axis=1))\n",
    "\n",
    "# Print classification reports\n",
    "print(\"HardC Classification Report:\")\n",
    "print(classification_report(y_true_numerical, y_pred_hardc))\n",
    "\n",
    "print(\"\\nCNN Classification Report:\")\n",
    "print(classification_report(y_true_numerical, y_pred_cnn))\n",
    "\n",
    "print(\"\\nLSTM Classification Report:\")\n",
    "print(classification_report(y_true_numerical, y_pred_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb18344-8c9b-48e3-9fbc-5a81aed4bc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 2.1887 - val_accuracy: 0.9311 - val_loss: 0.2672\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.2512 - val_accuracy: 0.9466 - val_loss: 0.2700\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.2314 - val_accuracy: 0.9444 - val_loss: 0.2054\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1998 - val_accuracy: 0.9541 - val_loss: 0.1732\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1964 - val_accuracy: 0.9450 - val_loss: 0.1863\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1685 - val_accuracy: 0.9505 - val_loss: 0.1658\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9535 - loss: 0.1670 - val_accuracy: 0.9566 - val_loss: 0.1437\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9575 - loss: 0.1442 - val_accuracy: 0.9606 - val_loss: 0.1342\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9588 - loss: 0.1362 - val_accuracy: 0.9472 - val_loss: 0.1541\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.1355 - val_accuracy: 0.9599 - val_loss: 0.1313\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9118 - loss: 1.2514 - val_accuracy: 0.9429 - val_loss: 0.2362\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.2060 - val_accuracy: 0.9519 - val_loss: 0.1542\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.1677 - val_accuracy: 0.9529 - val_loss: 0.1408\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9565 - loss: 0.1423 - val_accuracy: 0.9642 - val_loss: 0.1220\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9617 - loss: 0.1261 - val_accuracy: 0.9687 - val_loss: 0.1056\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9696 - loss: 0.1028 - val_accuracy: 0.9755 - val_loss: 0.0891\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9738 - loss: 0.0904 - val_accuracy: 0.9751 - val_loss: 0.0836\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9749 - loss: 0.0829 - val_accuracy: 0.9731 - val_loss: 0.0851\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.0820 - val_accuracy: 0.9754 - val_loss: 0.0846\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0740 - val_accuracy: 0.9759 - val_loss: 0.0827\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 14ms/step - accuracy: 0.8571 - loss: 1.2932 - val_accuracy: 0.9153 - val_loss: 0.3706\n",
      "Epoch 2/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step - accuracy: 0.9163 - loss: 0.3217 - val_accuracy: 0.9263 - val_loss: 0.2586\n",
      "Epoch 3/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.9221 - loss: 0.2906 - val_accuracy: 0.9263 - val_loss: 0.2652\n",
      "Epoch 4/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.9257 - loss: 0.2740 - val_accuracy: 0.9271 - val_loss: 0.2734\n",
      "Epoch 5/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.9289 - loss: 0.2582 - val_accuracy: 0.9279 - val_loss: 9.3730\n",
      "Epoch 6/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.8938 - loss: 1.9301 - val_accuracy: 0.9243 - val_loss: 0.2572\n",
      "Epoch 7/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15ms/step - accuracy: 0.9261 - loss: 0.2626 - val_accuracy: 0.9364 - val_loss: 0.2276\n",
      "Epoch 8/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.9313 - loss: 0.2370 - val_accuracy: 0.9324 - val_loss: 0.2505\n",
      "Epoch 9/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15ms/step - accuracy: 0.9307 - loss: 0.2386 - val_accuracy: 0.9375 - val_loss: 0.2183\n",
      "Epoch 10/10\n",
      "\u001b[1m2518/2518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 14ms/step - accuracy: 0.9281 - loss: 0.2493 - val_accuracy: 0.9270 - val_loss: 0.2429\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:224\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:158\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m lstm_model\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_reshaped, y_test))\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Encode test labels\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m y_test_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mtransform(np\u001b[38;5;241m.\u001b[39margmax(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Make predictions using each model\u001b[39;00m\n\u001b[0;32m     68\u001b[0m y_pred_hardc_prob \u001b[38;5;241m=\u001b[39m hardc_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:139\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _encode(y, uniques\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:226\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MIT-BIH Arrhythmia dataset\n",
    "# Assuming 'mitbih.csv' is your dataset file\n",
    "dataset_path = 'MITBIH.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df.drop(['type'], axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN and LSTM\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the HardC model\n",
    "hardc_model = Sequential()\n",
    "hardc_model.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "hardc_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "hardc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the HardC model\n",
    "hardc_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the CNN model\n",
    "cnn_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Build the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "lstm_model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the LSTM model\n",
    "lstm_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Encode test labels\n",
    "y_test_encoded = label_encoder.transform(np.argmax(y_test, axis=1))\n",
    "\n",
    "# Make predictions using each model\n",
    "y_pred_hardc_prob = hardc_model.predict(X_test)\n",
    "y_pred_hardc = np.argmax(y_pred_hardc_prob, axis=1)\n",
    "\n",
    "y_pred_cnn_prob = cnn_model.predict(X_test_reshaped)\n",
    "y_pred_cnn = np.argmax(y_pred_cnn_prob, axis=1)\n",
    "\n",
    "y_pred_lstm_prob = lstm_model.predict(X_test_reshaped)\n",
    "y_pred_lstm = np.argmax(y_pred_lstm_prob, axis=1)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"HardC Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_hardc))\n",
    "\n",
    "print(\"\\nCNN Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_cnn))\n",
    "\n",
    "print(\"\\nLSTM Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c37094-2ab2-4bb8-b3db-0205c26234c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.3515 - loss: 1.2107 - val_accuracy: 0.3600 - val_loss: 1.1077\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3565 - loss: 1.1577 - val_accuracy: 0.3800 - val_loss: 1.1030\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4115 - loss: 1.0915 - val_accuracy: 0.3200 - val_loss: 1.1143\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4570 - loss: 1.0484 - val_accuracy: 0.3500 - val_loss: 1.0982\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4238 - loss: 1.0426 - val_accuracy: 0.3000 - val_loss: 1.1103\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4742 - loss: 1.0235 - val_accuracy: 0.3900 - val_loss: 1.1150\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4975 - loss: 1.0052 - val_accuracy: 0.3100 - val_loss: 1.1269\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5296 - loss: 0.9881 - val_accuracy: 0.3800 - val_loss: 1.1132\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5787 - loss: 0.9543 - val_accuracy: 0.3400 - val_loss: 1.1524\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5160 - loss: 0.9701 - val_accuracy: 0.3800 - val_loss: 1.1321\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.3610 - loss: 1.1047 - val_accuracy: 0.2600 - val_loss: 1.1190\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4385 - loss: 1.0742 - val_accuracy: 0.3200 - val_loss: 1.1262\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5380 - loss: 1.0293 - val_accuracy: 0.3000 - val_loss: 1.1463\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5568 - loss: 0.9675 - val_accuracy: 0.2900 - val_loss: 1.2498\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5876 - loss: 0.9376 - val_accuracy: 0.3000 - val_loss: 1.1913\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6106 - loss: 0.8791 - val_accuracy: 0.3500 - val_loss: 1.2301\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7280 - loss: 0.7975 - val_accuracy: 0.3300 - val_loss: 1.2421\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6926 - loss: 0.7602 - val_accuracy: 0.3300 - val_loss: 1.3162\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7596 - loss: 0.6783 - val_accuracy: 0.3100 - val_loss: 1.4098\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7926 - loss: 0.6264 - val_accuracy: 0.2700 - val_loss: 1.3950\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 10, 10, 3), dtype=float32). Expected shape (None, 10, 3), but input has incompatible shape (None, 10, 10, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 10, 10, 3), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_encoded, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     50\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m create_lstm_model()\n\u001b[1;32m---> 51\u001b[0m lstm_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_encoded, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Encode test labels\u001b[39;00m\n\u001b[0;32m     54\u001b[0m y_test_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mtransform(y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:280\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    279\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 10, 10, 3), dtype=float32). Expected shape (None, 10, 3), but input has incompatible shape (None, 10, 10, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 10, 10, 3), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, LSTM\n",
    "\n",
    "# Dummy data (replace with your actual data)\n",
    "X_train, y_train = np.random.rand(1000, 10, 10, 3), np.random.randint(0, 3, 1000)\n",
    "X_test, y_test = np.random.rand(200, 10, 10, 3), np.random.randint(0, 3, 200)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Model definitions\n",
    "def create_hardc_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(10, 10, 3)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(10, 10, 3)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_lstm_model():\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(10, 3)),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model training\n",
    "hardc_model = create_hardc_model()\n",
    "hardc_model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "cnn_model = create_cnn_model()\n",
    "cnn_model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "lstm_model = create_lstm_model()\n",
    "lstm_model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Encode test labels\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Make predictions using each model\n",
    "y_pred_hardc_prob = hardc_model.predict(X_test)\n",
    "y_pred_hardc = np.argmax(y_pred_hardc_prob, axis=1)\n",
    "\n",
    "y_pred_cnn_prob = cnn_model.predict(X_test)\n",
    "y_pred_cnn = np.argmax(y_pred_cnn_prob, axis=1)\n",
    "\n",
    "y_pred_lstm_prob = lstm_model.predict(X_test)\n",
    "y_pred_lstm = np.argmax(y_pred_lstm_prob, axis=1)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"HardC Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_hardc))\n",
    "\n",
    "print(\"\\nCNN Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_cnn))\n",
    "\n",
    "print(\"\\nLSTM Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88ad5bf-c3a7-4da5-9fdf-a27c09ce995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 30 and 10 for '{{node sequential_12_1/lstm_4_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_12_1/lstm_4_1/strided_slice_2, sequential_12_1/lstm_4_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [?,30], [10,256].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(None, 30), dtype=float32)\n  • states=('tf.Tensor(shape=(None, 64), dtype=float32)', 'tf.Tensor(shape=(None, 64), dtype=float32)')\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[0;32m     29\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m create_lstm_model()\n\u001b[1;32m---> 30\u001b[0m lstm_model\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, y_train_encoded, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Assuming you have similar functions to create and train other models like CNN\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Example CNN model\u001b[39;00m\n\u001b[0;32m     35\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     36\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]),\n\u001b[0;32m     37\u001b[0m     Flatten(),\n\u001b[0;32m     38\u001b[0m     Dense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     39\u001b[0m     Dense(\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_train)), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m ])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 30 and 10 for '{{node sequential_12_1/lstm_4_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_12_1/lstm_4_1/strided_slice_2, sequential_12_1/lstm_4_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [?,30], [10,256].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(None, 30), dtype=float32)\n  • states=('tf.Tensor(shape=(None, 64), dtype=float32)', 'tf.Tensor(shape=(None, 64), dtype=float32)')\n  • training=True"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Flatten, Conv2D\n",
    "\n",
    "# Assuming you have already loaded your data into X_train, X_test, y_train, and y_test\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Function to create LSTM model\n",
    "def create_lstm_model():\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reshape the input data for LSTM model\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], -1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], -1)\n",
    "\n",
    "# Model training\n",
    "lstm_model = create_lstm_model()\n",
    "lstm_model.fit(X_train_reshaped, y_train_encoded, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Assuming you have similar functions to create and train other models like CNN\n",
    "\n",
    "# Example CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=X_train.shape[1:]),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model training\n",
    "cnn_model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e488c4-84f7-4e3f-8229-f2ae5e20da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.3374 - loss: 1.1056 - val_accuracy: 0.3600 - val_loss: 1.0915\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3535 - loss: 1.0979 - val_accuracy: 0.3600 - val_loss: 1.0906\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3560 - loss: 1.1009 - val_accuracy: 0.3500 - val_loss: 1.0961\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3649 - loss: 1.0952 - val_accuracy: 0.3900 - val_loss: 1.0957\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3646 - loss: 1.0939 - val_accuracy: 0.3600 - val_loss: 1.0936\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3512 - loss: 1.1044 - val_accuracy: 0.3600 - val_loss: 1.0925\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3394 - loss: 1.1031 - val_accuracy: 0.3600 - val_loss: 1.0935\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3506 - loss: 1.0947 - val_accuracy: 0.3700 - val_loss: 1.0958\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3445 - loss: 1.0926 - val_accuracy: 0.3600 - val_loss: 1.0969\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3945 - loss: 1.0806 - val_accuracy: 0.3100 - val_loss: 1.1130\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.2760 - loss: 1.1530 - val_accuracy: 0.3800 - val_loss: 1.1044\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3963 - loss: 1.0810 - val_accuracy: 0.3500 - val_loss: 1.1027\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4897 - loss: 1.0207 - val_accuracy: 0.3500 - val_loss: 1.1320\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5677 - loss: 0.9512 - val_accuracy: 0.3600 - val_loss: 1.1486\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6160 - loss: 0.8745 - val_accuracy: 0.3100 - val_loss: 1.1479\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6919 - loss: 0.7689 - val_accuracy: 0.3100 - val_loss: 1.2072\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7483 - loss: 0.7052 - val_accuracy: 0.3300 - val_loss: 1.1954\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7988 - loss: 0.6317 - val_accuracy: 0.3500 - val_loss: 1.2593\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8105 - loss: 0.5827 - val_accuracy: 0.3700 - val_loss: 1.3787\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8495 - loss: 0.4997 - val_accuracy: 0.3300 - val_loss: 1.4771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22b80e1f790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Flatten, Conv2D\n",
    "\n",
    "# Assuming you have already loaded your data into X_train, X_test, y_train, and y_test\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Function to create LSTM model\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reshape the input data for LSTM model\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], -1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], -1)\n",
    "\n",
    "# Model training\n",
    "lstm_model = create_lstm_model(input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_model.fit(X_train_reshaped, y_train_encoded, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Assuming you have similar functions to create and train other models like CNN\n",
    "\n",
    "# Example CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=X_train.shape[1:]),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model training\n",
    "cnn_model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc19955a-b149-49da-882f-c511b1ed624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n",
      "WARNING:tensorflow:5 out of the last 638 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000022B81464B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m cnn_y_pred_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(cnn_y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Get the true labels\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test_encoded, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Generate classification reports\u001b[39;00m\n\u001b[0;32m     18\u001b[0m lstm_report \u001b[38;5;241m=\u001b[39m classification_report(true_labels, lstm_y_pred_classes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have already trained your models and obtained predictions\n",
    "# lstm_model and cnn_model are assumed to be your trained models\n",
    "\n",
    "# Make predictions using the LSTM model\n",
    "lstm_y_pred = lstm_model.predict(X_test_reshaped)\n",
    "lstm_y_pred_classes = np.argmax(lstm_y_pred, axis=1)\n",
    "\n",
    "# Make predictions using the CNN model\n",
    "cnn_y_pred = cnn_model.predict(X_test)\n",
    "cnn_y_pred_classes = np.argmax(cnn_y_pred, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Generate classification reports\n",
    "lstm_report = classification_report(true_labels, lstm_y_pred_classes)\n",
    "cnn_report = classification_report(true_labels, cnn_y_pred_classes)\n",
    "\n",
    "print(\"LSTM Model Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "print(\"\\nCNN Model Classification Report:\")\n",
    "print(cnn_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9edb4ef-0b5b-4aa3-b4e3-e4e05430a163",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m cnn_y_pred_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(cnn_y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Get the true labels\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test_encoded, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Generate classification reports\u001b[39;00m\n\u001b[0;32m     11\u001b[0m lstm_report \u001b[38;5;241m=\u001b[39m classification_report(true_labels, lstm_y_pred_classes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have the predictions from your LSTM and CNN models\n",
    "lstm_y_pred_classes = np.argmax(lstm_y_pred, axis=1)\n",
    "cnn_y_pred_classes = np.argmax(cnn_y_pred, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Generate classification reports\n",
    "lstm_report = classification_report(true_labels, lstm_y_pred_classes)\n",
    "cnn_report = classification_report(true_labels, cnn_y_pred_classes)\n",
    "\n",
    "print(\"LSTM Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "print(\"\\nCNN Classification Report:\")\n",
    "print(cnn_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
